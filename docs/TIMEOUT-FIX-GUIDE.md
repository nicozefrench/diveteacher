# ğŸ”§ Document Processing Timeout Fix

**Date**: October 28, 2025  
**Issue**: First document upload times out after 5 minutes  
**Root Cause**: Docling model download takes 10-15 minutes on first run  
**Status**: âœ… FIXED with 3-layer solution

---

## ğŸ”´ Problem Analysis

### Symptoms
- Document stuck at "Validation - In progress..." for 15+ minutes
- Backend logs show: `TimeoutError: â±ï¸ Conversion timeout after 300s`
- Processing never starts because model download triggers timeout

### Root Cause
```
Timeline:
1. User uploads "Niveau 1.pdf"
2. Backend starts Docling conversion
3. Docling needs to download recognition models (first time only)
4. Model download takes 10-15 minutes
5. Timeout (300s = 5 min) kills the process
6. Document marked as failed
```

**Key Insight**: Model download time isn't counted as "processing" but blocks it entirely.

---

## âœ… Solution Implementation

### **Solution 1: Increase Conversion Timeout** â­

**File**: `backend/app/core/config.py`

```python
# Before
DOCLING_TIMEOUT: int = 300  # 5 minutes

# After
DOCLING_TIMEOUT: int = 900  # 15 minutes (allows for model download on first run)
```

**Impact**:
- âœ… Immediate fix - no rebuild needed
- âœ… First upload now has time to complete
- âœ… Subsequent uploads unaffected (models cached)

**Applied**: âœ… Backend restarted with new timeout

---

### **Solution 2: Docker Warm-up Script** â­â­

**Purpose**: Pre-download Docling models at container startup

**New Files**:

1. **`backend/warmup_docling.py`**
   - Downloads all Docling models before FastAPI starts
   - Logs progress with detailed output
   - Non-blocking - failures don't prevent startup

2. **`backend/docker-entrypoint.sh`**
   - Runs warm-up script first
   - Then starts FastAPI application
   - Can be disabled with `SKIP_WARMUP=true` env var

3. **`backend/Dockerfile`** (modified)
   - Copies warm-up script and entrypoint
   - Sets entrypoint to custom script

**How It Works**:
```bash
Container Start
    â†“
ğŸ”¥ Warm-up Phase (5-15 min first time)
    â”œâ”€â”€ Download recognition models
    â”œâ”€â”€ Cache models in /root/.cache/
    â””â”€â”€ Log completion
    â†“
ğŸš€ FastAPI Starts
    â”œâ”€â”€ Models already cached
    â””â”€â”€ First upload is fast!
```

**Activation**:
```bash
# Rebuild backend with warm-up
docker compose -f docker/docker-compose.dev.yml build backend

# Or skip warm-up if needed
docker compose -f docker/docker-compose.dev.yml up -e SKIP_WARMUP=true
```

**Impact**:
- âœ… Models ready before any upload
- âœ… First upload as fast as subsequent ones
- âœ… Better user experience
- âš ï¸  Initial container start takes longer (one-time cost)

**Status**: ğŸ“ Ready to build (requires rebuild to activate)

---

### **Solution 3: Enhanced UI Feedback** â­â­â­

**Purpose**: Better user communication during long conversions

**Changes**:

1. **`frontend/src/components/upload/DocumentItem.jsx`**
   - Added info banner during conversion stage
   - Displays: "First upload may take 5-15 minutes while AI models are downloaded"
   - Only shows during 'conversion' stage
   - Reassures user that subsequent uploads will be faster

2. **`frontend/src/components/upload/UploadTab.jsx`**
   - Added auto-retry mechanism for timeout errors
   - Max 2 automatic retries (3 total attempts)
   - 5-second delay between retries
   - Tracks retry attempts per document
   - Shows retry status in UI

**Auto-Retry Logic**:
```javascript
If timeout detected:
  â””â”€â”€ Attempt < 2?
      â”œâ”€â”€ Yes: Wait 5s â†’ Retry â†’ Show "Retrying (attempt X/3)..."
      â””â”€â”€ No: Stop and show manual retry button
```

**Impact**:
- âœ… Users informed about expected wait time
- âœ… Automatic recovery from timeouts
- âœ… Manual retry still available as fallback
- âœ… Better perceived performance

**Applied**: âœ… Frontend updated (no rebuild needed)

---

## ğŸ“Š Testing Plan

### Test Scenario 1: Fresh Container (No Models Cached)

**Setup**:
```bash
# Clean Docker volumes to simulate first run
docker compose -f docker/docker-compose.dev.yml down -v
docker compose -f docker/docker-compose.dev.yml up -d
```

**Expected Behavior**:
1. Container starts
2. Warm-up runs (if Solution 2 deployed) - 10-15 min
3. Upload "Niveau 1.pdf"
4. Conversion completes within 15 min timeout
5. Success!

### Test Scenario 2: Models Already Cached

**Expected Behavior**:
1. Upload "Niveau 1.pdf"
2. Conversion completes in < 2 minutes
3. No timeout
4. Success!

### Test Scenario 3: Timeout Still Occurs (Edge Case)

**Expected Behavior**:
1. Upload times out
2. UI shows auto-retry message: "Retrying (attempt 2/3)..."
3. Second attempt succeeds (models now cached)
4. Success!

---

## ğŸ¯ Success Criteria

- [x] Solution 1: Backend timeout increased to 900s âœ…
- [ ] Solution 2: Warm-up script ready (pending rebuild)
- [x] Solution 3: UI feedback enhanced âœ…
- [ ] Test: Fresh upload completes successfully
- [ ] Test: Subsequent uploads are fast (< 2 min)

---

## ğŸš€ Deployment Instructions

### Immediate (Solutions 1 & 3 - DONE âœ…)
```bash
# Already applied - backend restarted
cd /Users/nicozefrench/Dropbox/AI/rag-knowledge-graph-starter
docker compose -f docker/docker-compose.dev.yml restart backend
```

### Next Steps (Solution 2 - Optional but Recommended)
```bash
# Rebuild backend with warm-up script
docker compose -f docker/docker-compose.dev.yml build backend

# Restart with new image
docker compose -f docker/docker-compose.dev.yml up -d backend

# Watch warm-up progress
docker logs -f rag-backend
```

**Note**: Solution 2 is optional but highly recommended for production. It eliminates the first-upload delay entirely.

---

## ğŸ“ˆ Performance Comparison

| Scenario | Before Fix | After Fix (Solution 1) | After Fix (Solutions 1+2) |
|----------|------------|------------------------|----------------------------|
| **First Upload** | âŒ Timeout (5 min) | âœ… Success (10-15 min) | âœ… Success (< 2 min) |
| **Second Upload** | âœ… Fast (1-2 min) | âœ… Fast (1-2 min) | âœ… Fast (1-2 min) |
| **User Experience** | Poor (confusing) | Good (works, but slow) | Excellent (consistent) |

---

## ğŸ” Verification

### Check Current Timeout
```bash
docker exec rag-backend python3 -c "from app.core.config import settings; print(f'Timeout: {settings.DOCLING_TIMEOUT}s')"
# Expected: Timeout: 900s
```

### Monitor Next Upload
```bash
# Watch backend logs during upload
docker logs -f rag-backend | grep -E "(Niveau|process|timeout|Download)"
```

### Check Model Cache
```bash
# After successful upload, check if models are cached
docker exec rag-backend ls -lh /root/.cache/
```

---

## ğŸ“ Lessons Learned

1. **First-run penalties**: Always account for model/dependency downloads in timeouts
2. **Warm-up patterns**: Pre-loading heavy resources improves UX significantly
3. **Progressive enhancement**: Layer solutions (quick fix + proper fix + UX fix)
4. **Transparent feedback**: Users tolerate delays when they understand why

---

## ğŸ“ Related Files

- `backend/app/core/config.py` - Timeout configuration
- `backend/app/core/processor.py` - Document processing logic
- `backend/warmup_docling.py` - Model warm-up script (new)
- `backend/docker-entrypoint.sh` - Container entrypoint (new)
- `backend/Dockerfile` - Docker build configuration (modified)
- `frontend/src/components/upload/DocumentItem.jsx` - UI feedback (modified)
- `frontend/src/components/upload/UploadTab.jsx` - Auto-retry logic (modified)

---

**Next Action**: Test the current fix (Solutions 1 & 3) by uploading a document!

