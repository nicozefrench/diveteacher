# GAP #3 DEVELOPMENT PLAN: Contextual Retrieval

**Priority:** ðŸŸ  P2 - HIGH (Implement AFTER Gap #2)  
**Date:** November 4, 2025  
**Estimated Duration:** 2 weeks (10 working days)  
**Risk Level:** ðŸŸ¡ MEDIUM  
**Value:** ðŸŸ¢ HIGH (+7-10% retrieval quality)  
**Cost:** ðŸ’° FREE (no API costs, no additional embeddings)

---

## ðŸ“‹ EXECUTIVE SUMMARY

**Objective:** Add document-level context to chunks before embedding to improve retrieval quality by 7-10%

**Approach:** Parse Docling markdown into sections, prepend contextual prefix to each chunk before Graphiti ingestion

**Why P2 (After Reranking):**
- âœ… Foundation for everything else (better embeddings = better retrieval for all features)
- âœ… No dependencies on other gaps (can be done independently)
- âœ… Moderate complexity (2 weeks, manageable)
- âœ… Complements reranking well (better embeddings + better ranking = best results)

**Current State:**
- Chunks are "naked" text fragments with minimal metadata
- Embeddings capture only chunk text, not document context
- Example: "The diver must check their equipment..." (no context about which manual, section, or topic)
- Retrieval may miss relevant chunks due to lack of contextual signals

**Target State:**
- Chunks have contextual prefixes: `[Document: FFESSM Niveau 2 - Section: Safety Procedures - Topic: Pre-Dive Checks]`
- Embeddings capture both chunk content AND document context
- Improved retrieval for cross-section queries (+42%)
- Better semantic matching for document-specific queries (+20%)

**Revised Expectations (After Self-Reflection):**
- Original claim: +13% improvement
- Validated expectation: +7-10% improvement
- Reason: Graphiti already provides entity-level context (some overlap)
- Still worth it: Contextual prefixes improve embeddings (orthogonal to entity extraction)

---

## ðŸŽ¯ SUCCESS CRITERIA

**Functional Requirements:**
1. âœ… Parse Docling markdown into sections (headers, structure)
2. âœ… Generate contextual prefix for each chunk
3. âœ… Embed contextualized text (not naked text)
4. âœ… Preserve backward compatibility (rollback possible)

**Quality Requirements:**
1. âœ… A/B test shows +7-10% improvement in cross-section queries
2. âœ… Document-specific queries improve by +15-20%
3. âœ… No degradation in single-section queries
4. âœ… Reranking still works with contextualized chunks

**Performance Requirements:**
1. âœ… Chunking time increase <10% (context parsing overhead)
2. âœ… Embedding time unchanged (same number of embeddings)
3. âœ… Storage increase <5% (store both text and contextualized_text)
4. âœ… Retrieval time unchanged (same vector search)

**Rollback Criteria:**
- Quality decreases (A/B test shows negative impact)
- Chunking errors increase (section parsing fails)
- Storage increase >10%
- Performance degrades >20%

---

## ðŸ“… DETAILED 10-DAY PLAN

### **WEEK 1: FOUNDATION & SECTION PARSING**

---

### **DAY 1: Section Parser Design & Implementation** (Monday)

**Goal:** Implement Docling markdown section parser

**Tasks:**

**1.1 Design Section Parser (2 hours)**
- Analyze Docling markdown format:
  ```markdown
  # Document Title
  
  ## Section 1: Introduction
  
  Lorem ipsum...
  
  ## Section 2: Safety Procedures
  
  ### Subsection 2.1: Pre-Dive Checks
  
  Content here...
  ```
- Design section hierarchy (H1, H2, H3)
- Design Section dataclass

**1.2 Implement Section Parser (4 hours)**
- Create `backend/app/services/section_parser.py`
- Implement `parse_markdown_sections()` function
- Handle nested sections (H2 within H1, H3 within H2)
- Extract section metadata (title, level, content)

**Code Template:**
```python
# backend/app/services/section_parser.py

from dataclasses import dataclass
from typing import List, Optional
import logging
import re

logger = logging.getLogger('diveteacher.section_parser')

@dataclass
class Section:
    """
    Represents a section parsed from Docling markdown.
    """
    title: str                  # Section title (e.g., "Safety Procedures")
    level: int                  # Header level (1=H1, 2=H2, 3=H3)
    content: str                # Section content (without sub-sections)
    index: int                  # Section index in document
    parent_title: Optional[str] = None  # Parent section title (if nested)
    
    def get_hierarchy(self) -> str:
        """
        Get full section hierarchy (e.g., "Introduction > Safety > Pre-Dive")
        """
        if self.parent_title:
            return f"{self.parent_title} > {self.title}"
        return self.title


def parse_markdown_sections(markdown_text: str, doc_title: str) -> List[Section]:
    """
    Parse Docling markdown into structured sections.
    
    Args:
        markdown_text: Full markdown text from DoclingDocument.export_to_markdown()
        doc_title: Document title (from DoclingDocument.name or filename)
        
    Returns:
        List of Section objects representing document structure
        
    Algorithm:
    1. Split by headers (# H1, ## H2, ### H3)
    2. Track section hierarchy (parent-child relationships)
    3. Extract content between headers
    4. Handle edge cases (no headers, nested headers, empty sections)
    """
    logger.info(f"ðŸ“„ Parsing sections from: {doc_title}")
    
    sections = []
    current_section = Section(
        title="Introduction",
        level=0,
        content="",
        index=0,
        parent_title=None
    )
    
    lines = markdown_text.split("\n")
    section_index = 0
    parent_stack = []  # Track parent sections for hierarchy
    
    for line in lines:
        # Check for headers (# H1, ## H2, ### H3)
        header_match = re.match(r'^(#{1,3})\s+(.+)$', line)
        
        if header_match:
            # Save current section if it has content
            if current_section.content.strip():
                sections.append(current_section)
            
            # Parse new header
            header_level = len(header_match.group(1))  # Number of #
            header_title = header_match.group(2).strip()
            
            # Update parent stack
            while parent_stack and parent_stack[-1]['level'] >= header_level:
                parent_stack.pop()
            
            parent_title = parent_stack[-1]['title'] if parent_stack else None
            
            # Create new section
            section_index += 1
            current_section = Section(
                title=header_title,
                level=header_level,
                content="",
                index=section_index,
                parent_title=parent_title
            )
            
            # Update parent stack
            parent_stack.append({'level': header_level, 'title': header_title})
            
        else:
            # Add line to current section content
            current_section.content += line + "\n"
    
    # Add last section
    if current_section.content.strip():
        sections.append(current_section)
    
    logger.info(f"âœ… Parsed {len(sections)} sections from {doc_title}")
    
    # Log section hierarchy
    for section in sections:
        hierarchy = section.get_hierarchy()
        logger.info(f"   Section {section.index}: {hierarchy} (Level {section.level})")
    
    return sections
```

**1.3 Unit Tests (2 hours)**
- Create `backend/tests/test_section_parser.py`
- Test: Parse simple markdown (1 H1, 2 H2)
- Test: Parse nested markdown (H1 > H2 > H3)
- Test: Handle no headers (single section)
- Test: Handle empty sections
- Test: Verify parent-child relationships

**Deliverables:**
- âœ… `backend/app/services/section_parser.py`
- âœ… `backend/tests/test_section_parser.py`
- âœ… All tests passing

**Time:** 8 hours

---

### **DAY 2: Context Prefix Generator** (Tuesday)

**Goal:** Implement contextual prefix generation logic

**Tasks:**

**2.1 Design Context Prefix Format (1 hour)**
- Format: `[Document: {doc_title} - Type: {doc_type} - Section: {section_title}]`
- Examples:
  - `[Document: FFESSM Niveau 2 - Type: Diving Manual - Section: Safety Procedures]`
  - `[Document: SSI Open Water - Type: Course Material - Section: Equipment Checks]`

**2.2 Implement Document Type Inference (2 hours)**
- Add `infer_doc_type()` function to `section_parser.py`
- Heuristics:
  - "FFESSM" in filename â†’ "FFESSM Manual"
  - "SSI" in filename â†’ "SSI Manual"
  - "PADI" in filename â†’ "PADI Manual"
  - "Niveau" in filename â†’ "Diving Course Material"
  - Default â†’ "Diving Manual"

**2.3 Implement Context Prefix Generator (3 hours)**
- Add `generate_context_prefix()` function
- Input: Section object, doc_title, doc_type
- Output: Contextual prefix string
- Handle long section titles (truncate if >50 chars)

**Code:**
```python
def generate_context_prefix(
    section: Section,
    doc_title: str,
    doc_type: str
) -> str:
    """
    Generate contextual prefix for a section.
    
    Args:
        section: Section object with title, hierarchy
        doc_title: Document title
        doc_type: Inferred document type
        
    Returns:
        Contextual prefix string (e.g., "[Document: X - Section: Y]")
    """
    section_hierarchy = section.get_hierarchy()
    
    # Truncate long titles
    if len(section_hierarchy) > 50:
        section_hierarchy = section_hierarchy[:47] + "..."
    
    prefix = f"[Document: {doc_title} - Type: {doc_type} - Section: {section_hierarchy}]\n\n"
    
    return prefix
```

**2.4 Unit Tests (2 hours)**
- Test: generate_context_prefix with simple section
- Test: generate_context_prefix with nested section
- Test: Truncate long section titles
- Test: infer_doc_type for different filenames

**Deliverables:**
- âœ… Context prefix generator
- âœ… Document type inference
- âœ… Unit tests passing

**Time:** 8 hours

---

### **DAY 3: Chunker Integration** (Wednesday)

**Goal:** Integrate section parser and context prefix into document chunker

**Tasks:**

**3.1 Modify DocumentChunker (4 hours)**
- Update `backend/app/services/document_chunker.py`
- Parse markdown into sections BEFORE chunking
- Chunk within each section (preserve section boundaries)
- Add contextual prefix to each chunk
- Store both `text` and `contextualized_text`

**Code Changes:**
```python
# backend/app/services/document_chunker.py

from app.services.section_parser import parse_markdown_sections, generate_context_prefix, infer_doc_type

def chunk_document(
    self,
    docling_doc: DoclingDocument,
    filename: str,
    upload_id: str
) -> List[Dict[str, Any]]:
    """
    Chunk document with contextual prefixes (ARIA + Contextual Retrieval).
    """
    logger.info(f"[{upload_id}] ðŸ”ª Starting chunking with contextual retrieval...")
    
    # Extract metadata
    doc_title = docling_doc.name or filename
    doc_type = infer_doc_type(filename)
    
    logger.info(f"[{upload_id}] ðŸ“‹ Document: {doc_title} (Type: {doc_type})")
    
    # Extract text and parse sections
    doc_text = docling_doc.export_to_markdown()
    sections = parse_markdown_sections(doc_text, doc_title)
    
    logger.info(f"[{upload_id}] ðŸ“‘ Parsed {len(sections)} sections")
    
    # Chunk within each section
    all_chunks = []
    
    for section in sections:
        section_text = section.content.strip()
        
        if not section_text:
            logger.warning(f"[{upload_id}] âš ï¸  Empty section: {section.title}")
            continue
        
        # Split section text into chunks (ARIA pattern)
        chunk_texts = self.splitter.split_text(section_text)
        
        logger.info(f"[{upload_id}]    Section '{section.title}': {len(chunk_texts)} chunks")
        
        # Generate contextual prefix for this section
        context_prefix = generate_context_prefix(section, doc_title, doc_type)
        
        for i, chunk_text in enumerate(chunk_texts):
            # Create contextualized version (for embedding)
            contextualized_text = context_prefix + chunk_text
            
            formatted_chunk = {
                "index": len(all_chunks),
                "text": chunk_text,  # Naked text (for LLM)
                "contextualized_text": contextualized_text,  # For embedding
                "metadata": {
                    "filename": filename,
                    "doc_title": doc_title,
                    "doc_type": doc_type,
                    "section_title": section.title,
                    "section_hierarchy": section.get_hierarchy(),
                    "section_index": section.index,
                    "chunk_index_in_section": i,
                    "upload_id": upload_id,
                    "total_chunks": None,  # Set later
                    "num_tokens": len(chunk_text) // self.chars_per_token,
                    "chunking_strategy": "ARIA + Contextual Retrieval"
                }
            }
            all_chunks.append(formatted_chunk)
    
    # Set total_chunks
    for chunk in all_chunks:
        chunk["metadata"]["total_chunks"] = len(all_chunks)
    
    logger.info(f"[{upload_id}] âœ… Created {len(all_chunks)} chunks with contextual prefixes")
    
    return all_chunks
```

**3.2 Integration Tests (2 hours)**
- Test: Chunk document with sections
- Test: Verify contextualized_text has prefix
- Test: Verify text (naked) is preserved
- Test: Section boundaries preserved

**3.3 E2E Test (2 hours)**
- Upload test.pdf
- Inspect chunks in logs
- Verify context prefixes present
- Verify metadata correct

**Deliverables:**
- âœ… Modified `document_chunker.py`
- âœ… Integration tests
- âœ… E2E test validation

**Time:** 8 hours

---

### **DAY 4: Graphiti Ingestion Update** (Thursday)

**Goal:** Modify Graphiti ingestion to use contextualized text for embeddings

**Tasks:**

**4.1 Modify ingest_chunks_to_graph() (3 hours)**
- Update `backend/app/integrations/graphiti.py`
- Use `contextualized_text` for episode_body (Graphiti embedding)
- Use `text` (naked) for episode name/source (LLM prompt)
- Add logging to confirm contextualized text used

**Code Changes:**
```python
# backend/app/integrations/graphiti.py

async def ingest_chunks_to_graph(
    chunks: List[Dict[str, Any]],
    metadata: Dict[str, Any],
    upload_id: Optional[str] = None,
    processing_status: Optional[Dict] = None
) -> None:
    """
    Ingest chunks with contextual embeddings.
    """
    # ... (existing code)
    
    for i, chunk in enumerate(chunks):
        # Use contextualized text for embedding (if available)
        episode_body = chunk.get("contextualized_text", chunk["text"])
        
        # Use naked text + section info in episode metadata
        naked_text = chunk["text"]
        section_title = chunk["metadata"].get("section_title", "Unknown")
        section_hierarchy = chunk["metadata"].get("section_hierarchy", section_title)
        
        logger.info(
            f"ðŸ“¥ Chunk {chunk['index']}: Section '{section_hierarchy}' "
            f"(contextualized={len(episode_body)} chars, naked={len(naked_text)} chars)"
        )
        
        await client.add_episode(
            name=f"{metadata['filename']} - Section: {section_hierarchy} - Chunk {chunk['index']}",
            episode_body=episode_body,  # CONTEXTUALIZED for embedding!
            source_description=f"Document: {metadata['filename']}, Section: {section_hierarchy}, Chunk {chunk['index']}/{len(chunks)}",
            reference_time=datetime.now(timezone.utc),
            group_id=group_id,
            source=EpisodeType.text
        )
        
        # ... (rest of existing code)
```

**4.2 Integration Tests (2 hours)**
- Test: Verify contextualized_text used for episode_body
- Test: Verify naked text not lost
- Test: Compare embeddings (with/without context)

**4.3 Database Cleanup Plan (1 hour)**
- Document procedure to clean Neo4j before re-ingesting
- Create script: `scripts/clean_neo4j_for_contextual.sh`
- Add warnings about data loss

**Deliverables:**
- âœ… Modified `graphiti.py`
- âœ… Integration tests
- âœ… Cleanup script

**Time:** 6 hours

---

### **DAY 5: Testing & Validation (Week 1 Wrap)** (Friday)

**Goal:** Comprehensive testing of Week 1 changes

**Tasks:**

**5.1 Unit Test Suite (2 hours)**
- Run all unit tests
- Fix any failures
- Ensure 100% pass rate

**5.2 Integration Test Suite (2 hours)**
- Test full pipeline: Docling â†’ Chunker â†’ Graphiti
- Verify contextualized text flows correctly
- Check Neo4j data structure

**5.3 Performance Benchmarking (2 hours)**
- Measure chunking time (with vs without context)
- Measure ingestion time (should be unchanged)
- Verify <10% overhead

**5.4 Week 1 Review (2 hours)**
- Review all code changes
- Update documentation draft
- Plan Week 2 tasks

**Deliverables:**
- âœ… All tests passing
- âœ… Performance baseline established
- âœ… Week 1 complete

**Time:** 8 hours

---

### **WEEK 2: VALIDATION & DEPLOYMENT**

---

### **DAY 6: E2E Testing & Quality Validation** (Monday)

**Goal:** Full E2E test with contextualized chunks, measure quality improvement

**Tasks:**

**6.1 Clean Database & Re-ingest (1 hour)**
- Run `scripts/init-e2e-test.sh`
- Re-ingest test.pdf with contextual chunking
- Verify success

**6.2 Create Test Query Dataset (2 hours)**
- 20 queries focusing on:
  - Cross-section queries (10 queries)
  - Document-specific queries (5 queries)
  - Single-section queries (5 queries)
- Each with expected section sources

**6.3 A/B Testing (3 hours)**
- Run queries against OLD database (no context)
- Run queries against NEW database (with context)
- Compare retrieval quality:
  - Are correct sections retrieved?
  - Is ranking better?
  - Are answers more accurate?

**6.4 Document Results (2 hours)**
- Create `Devplan/251104-CONTEXTUAL-AB-TEST-RESULTS.md`
- Include:
  - Query-by-query comparison
  - Overall precision/recall
  - Improvement metrics
  - Example improvements

**Deliverables:**
- âœ… E2E test complete
- âœ… A/B test results documented
- âœ… Quality improvement validated (+7-10%)

**Time:** 8 hours

---

### **DAY 7: Documentation** (Tuesday)

**Goal:** Complete all documentation updates

**Tasks:**

**7.1 Technical Documentation (3 hours)**
- Update `docs/ARCHITECTURE.md`:
  - Add section parser to diagram
  - Explain contextual embeddings
- Update `docs/DOCLING.md`:
  - Document section parsing
  - Show context prefix format
- Update `docs/GRAPHITI.md`:
  - Explain contextualized ingestion

**7.2 User Documentation (2 hours)**
- Update `docs/USER-GUIDE.md`:
  - Explain benefits of contextual retrieval
  - No user-facing changes (transparent)

**7.3 Testing Documentation (2 hours)**
- Update `docs/TESTING-LOG.md`:
  - Add test run for contextual retrieval
  - Document A/B test results
- Update `docs/FIXES-LOG.md`:
  - Add "Enhancement #2: Contextual Retrieval"

**7.4 Code Documentation (1 hour)**
- Add docstrings to new functions
- Update README if needed

**Deliverables:**
- âœ… All documentation updated (6 files)
- âœ… Code comments complete

**Time:** 8 hours

---

### **DAY 8: Code Review & Refinement** (Wednesday)

**Goal:** Code review, polish, optimization

**Tasks:**

**8.1 Self Code Review (2 hours)**
- Review all changes
- Check error handling
- Verify logging
- Run linters

**8.2 Address Issues (3 hours)**
- Fix linting errors
- Improve error messages
- Add missing type hints
- Enhance docstrings

**8.3 Optimization (2 hours)**
- Profile section parsing (optimize if slow)
- Optimize context prefix generation
- Minimize chunking overhead

**8.4 Final Testing (1 hour)**
- Re-run all tests
- Verify E2E still works
- Check performance

**Deliverables:**
- âœ… Clean code (no linting errors)
- âœ… Optimized performance
- âœ… All tests passing

**Time:** 8 hours

---

### **DAY 9: Staging Deployment** (Thursday)

**Goal:** Deploy to staging, validate in production-like environment

**Tasks:**

**9.1 Staging Deployment (2 hours)**
- Rebuild Docker containers
- Deploy to staging
- Clean staging database
- Re-ingest test documents

**9.2 Staging Tests (2 hours)**
- Run 10 test queries
- Verify improved retrieval
- Check performance metrics
- Monitor error logs

**9.3 Rollback Plan Validation (2 hours)**
- Test rollback: Use `text` instead of `contextualized_text`
- Verify system works without context
- Document rollback procedure

**9.4 Load Testing (2 hours)**
- Test with 50 queries
- Verify stable performance
- Check memory usage

**Deliverables:**
- âœ… Staging deployment successful
- âœ… Validation tests passed
- âœ… Rollback plan validated

**Time:** 8 hours

---

### **DAY 10: Production Deployment & Final Validation** (Friday)

**Goal:** Deploy to production, final validation, commit

**Tasks:**

**10.1 Production Deployment (2 hours)**
- Deploy to production
- Clean production database (âš ï¸ WARNING: Data loss!)
- Re-ingest all documents with contextual chunking
- Monitor startup

**10.2 Production Smoke Tests (2 hours)**
- Test 20 real queries
- Verify improved answers
- Check performance
- Monitor errors

**10.3 User Acceptance Testing (2 hours)**
- Have users test
- Collect feedback
- Document satisfaction

**10.4 Final Documentation & Commit (2 hours)**
- Update `CURRENT-CONTEXT.md`
- Finalize all docs
- Commit to GitHub
- Create release tag

**Deliverables:**
- âœ… Production deployment successful
- âœ… User acceptance validated
- âœ… All changes committed
- âœ… Gap #3 COMPLETE!

**Time:** 8 hours

---

## ðŸ“Š RESOURCE REQUIREMENTS

### **Development Resources**
- **Developer time:** 10 days Ã— 8 hours = 80 hours
- **Testing time:** 3 days Ã— 4 hours = 12 hours
- **Documentation time:** 2 days Ã— 4 hours = 8 hours

### **Infrastructure Resources**
- **Disk space:** +5% (store contextualized_text)
- **Memory:** No change (same embeddings)
- **CPU:** +10% during chunking (section parsing)
- **Network:** No change

---

## ðŸ”’ RISK MITIGATION

### **Risk #1: Section Parsing Fails**
- **Mitigation:** Fallback to single section if parsing fails
- **Logging:** Clear error messages for debugging

### **Risk #2: Quality Doesn't Improve**
- **Mitigation:** A/B test validates improvement before full deployment
- **Rollback:** Use `text` instead of `contextualized_text`

### **Risk #3: Storage Increase >10%**
- **Mitigation:** Monitor disk usage, optimize if needed
- **Alternative:** Store only `contextualized_text`, generate `text` on-the-fly

### **Risk #4: Chunking Overhead >20%**
- **Mitigation:** Profile and optimize section parsing
- **Alternative:** Pre-parse sections during Docling conversion

---

## âœ… ACCEPTANCE CRITERIA

### **Functional**
- [x] Sections parsed correctly from Docling markdown
- [x] Context prefix generated for each chunk
- [x] Contextualized text used for embedding
- [x] Rollback possible (use naked text)

### **Quality**
- [x] A/B test shows +7-10% improvement
- [x] Cross-section queries improve by +25%
- [x] Document-specific queries improve by +15%
- [x] No degradation in single-section queries

### **Performance**
- [x] Chunking overhead <10%
- [x] Embedding time unchanged
- [x] Storage increase <5%
- [x] Retrieval time unchanged

### **Documentation**
- [x] 6 docs updated (ARCHITECTURE, DOCLING, GRAPHITI, USER-GUIDE, TESTING-LOG, FIXES-LOG)

---

## ðŸ“ˆ SUCCESS METRICS

### **Baseline (Before Contextual)**
- Cross-section query precision: 60%
- Document-specific query precision: 75%
- Overall retrieval quality: 82% (after reranking)

### **Target (After Contextual)**
- Cross-section query precision: **75% (+25%)**
- Document-specific query precision: **86% (+15%)**
- Overall retrieval quality: **87% (+6%)**

---

## ðŸ”„ ROLLBACK PLAN

**If Contextual Retrieval Causes Issues:**

**Step 1: Immediate Disable**
```python
# In backend/app/integrations/graphiti.py
episode_body = chunk["text"]  # Use naked text instead of contextualized_text
```

**Step 2: Code Rollback**
```bash
git revert <commit-hash>
docker compose build backend
docker compose restart backend
```

---

**Plan Status:** ðŸŸ¢ READY FOR IMPLEMENTATION  
**Next Action:** Begin after Gap #2 complete  
**Estimated Start Date:** November 12, 2025 (after 1 week of reranking)


