# Guide Complet Docling pour Agent IA Claude Sonnet 4.5

> **Document de r√©f√©rence pour l'utilisation de Docling dans un contexte de d√©veloppement avec agent IA**  
> Version: 1.0 | Date: 27 octobre 2025

---

## Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Architecture et Concepts Cl√©s](#architecture-et-concepts-cl√©s)
3. [Installation et Configuration](#installation-et-configuration)
4. [Utilisation de Base](#utilisation-de-base)
5. [Fonctionnalit√©s Avanc√©es](#fonctionnalit√©s-avanc√©es)
6. [Formats Support√©s](#formats-support√©s)
7. [Exportation et Transformation](#exportation-et-transformation)
8. [Int√©grations avec Frameworks IA](#int√©grations-avec-frameworks-ia)
9. [Chunking pour RAG](#chunking-pour-rag)
10. [Gestion des Ressources et Performance](#gestion-des-ressources-et-performance)
11. [Bonnes Pratiques pour Agents IA](#bonnes-pratiques-pour-agents-ia)
12. [R√©solution de Probl√®mes](#r√©solution-de-probl√®mes)
13. [Ressources et R√©f√©rences](#ressources-et-r√©f√©rences)

---

## Vue d'Ensemble

### Qu'est-ce que Docling?

Docling est une biblioth√®que open-source MIT cr√©√©e par IBM Research Zurich pour simplifier le traitement de documents. Elle permet de parser des documents de formats vari√©s avec une compr√©hension avanc√©e des PDFs, et fournit des int√©grations natives avec l'√©cosyst√®me Gen AI.

### Caract√©ristiques Principales

- üóÇÔ∏è **Multi-format**: PDF, DOCX, PPTX, XLSX, HTML, WAV, MP3, images (PNG, TIFF, JPEG, etc.)
- üìë **Compr√©hension PDF avanc√©e**: mise en page, ordre de lecture, structure de tables, code, formules, classification d'images
- üß¨ **Format unifi√©**: Repr√©sentation `DoclingDocument` expressive et unifi√©e
- ‚Ü™Ô∏è **Exports vari√©s**: Markdown, HTML, DocTags, JSON lossless
- üîí **Ex√©cution locale**: Pour donn√©es sensibles et environnements air-gapped
- ü§ñ **Int√©grations plug-and-play**: LangChain, LlamaIndex, Crew AI, Haystack
- üîç **OCR √©tendu**: Support complet pour PDFs scann√©s et images
- üëì **Visual Language Models**: Support de SmolDocling et autres VLMs
- üéôÔ∏è **Audio**: Automatic Speech Recognition (ASR)
- üíª **CLI pratique**: Interface en ligne de commande simple

### Mod√®les IA Utilis√©s

- **DocLayNet**: Analyse de mise en page (layout analysis)
- **TableFormer**: Reconnaissance de structure de tables
- **SmolDocling**: Visual Language Model l√©ger (256M param√®tres)
- **EasyOCR**: Reconnaissance optique de caract√®res
- Support pour mod√®les ASR (Automatic Speech Recognition)

---

## Architecture et Concepts Cl√©s

### Pipeline de Conversion

Docling utilise une architecture modulaire bas√©e sur des **backends** sp√©cialis√©s:

```
Document Source ‚Üí Backend Converter ‚Üí DoclingDocument ‚Üí Export Format
```

#### Backends Disponibles

- **PdfDocumentBackend**: Pour PDFs (backend principal)
- **DocxDocumentBackend**: Pour documents Word
- **PptxDocumentBackend**: Pour pr√©sentations PowerPoint
- **XlsxDocumentBackend**: Pour feuilles de calcul Excel
- **HTMLDocumentBackend**: Pour pages HTML
- **ImageDocumentBackend**: Pour images
- **AsciidocDocumentBackend**: Pour documents Asciidoc
- **AudioDocumentBackend**: Pour fichiers audio

### DoclingDocument

`DoclingDocument` est le format de repr√©sentation unifi√© au c≈ìur de Docling. Il capture:

- **Structure**: Hi√©rarchie des sections, paragraphes, listes, tables
- **Contenu**: Texte, images, formulas, code
- **M√©tadonn√©es**: Titre, auteurs, r√©f√©rences, langue
- **Provenance**: Bounding boxes, num√©ros de page
- **S√©mantique**: Classification des √©l√©ments (titres, texte, l√©gendes, etc.)

### Flux de Travail Typique

```python
from docling.document_converter import DocumentConverter

# 1. Initialiser le convertisseur
converter = DocumentConverter()

# 2. Convertir le document
result = converter.convert(source)

# 3. Acc√©der au DoclingDocument
doc = result.document

# 4. Exporter dans le format d√©sir√©
markdown_text = doc.export_to_markdown()
```

---

## Installation et Configuration

### Installation Standard

```bash
pip install docling
```

**Plateformes support√©es**: macOS, Linux, Windows  
**Architectures**: x86_64, arm64

### Installation pour D√©veloppement

```bash
git clone https://github.com/docling-project/docling.git
cd docling
pip install -e ".[dev]"
```

### D√©pendances Syst√®me

Pour OCR complet et fonctionnalit√©s avanc√©es:

```bash
# Ubuntu/Debian
sudo apt-get install tesseract-ocr

# macOS
brew install tesseract
```

### Configuration des Variables d'Environnement

```bash
# Chemin vers les artefacts de mod√®les (pour usage offline)
export DOCLING_ARTIFACTS_PATH="/path/to/models"

# Limiter les threads CPU utilis√©s (d√©faut: 4)
export OMP_NUM_THREADS=4
```

### T√©l√©chargement des Mod√®les (Usage Offline)

```bash
# M√©thode 1: CLI
docling-tools models download

# M√©thode 2: Programmatique
from docling.utils.model_downloader import download_models
download_models()
```

Les mod√®les sont t√©l√©charg√©s dans `$HOME/.cache/docling/models`.

---

## Utilisation de Base

### Conversion Simple

```python
from docling.document_converter import DocumentConverter

# Source peut √™tre: chemin local, URL, ou stream binaire
source = "https://arxiv.org/pdf/2408.09869"
converter = DocumentConverter()
result = converter.convert(source)

# Exporter en Markdown
markdown = result.document.export_to_markdown()
print(markdown)
```

### Conversion depuis Stream Binaire

```python
from io import BytesIO
from docling.datamodel.base_models import DocumentStream
from docling.document_converter import DocumentConverter

# Cr√©er un stream
buf = BytesIO(binary_pdf_data)
source = DocumentStream(name="document.pdf", stream=buf)

converter = DocumentConverter()
result = converter.convert(source)
```

### Conversion Batch (Multiple Documents)

```python
from pathlib import Path
from docling.document_converter import DocumentConverter

# Liste de documents √† convertir
sources = [
    "doc1.pdf",
    "doc2.docx",
    "https://example.com/doc3.pdf"
]

converter = DocumentConverter()

for source in sources:
    result = converter.convert(source)
    output_path = Path(source).stem + ".md"
    Path(output_path).write_text(result.document.export_to_markdown())
```

### Utilisation CLI

```bash
# Conversion simple
docling document.pdf

# Avec sp√©cification du format de sortie
docling --to markdown document.pdf

# Conversion d'un r√©pertoire
docling --output output_dir/ input_dir/

# Utilisation de SmolDocling VLM
docling --pipeline vlm --vlm-model smoldocling document.pdf

# Voir toutes les options
docling --help
```

**R√©f√©rence CLI**: https://docling-project.github.io/docling/reference/cli/

---

## Fonctionnalit√©s Avanc√©es

### Configuration du Pipeline PDF

```python
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.document_converter import DocumentConverter, PdfFormatOption

# Configuration personnalis√©e
pipeline_options = PdfPipelineOptions(
    do_ocr=True,                    # Activer OCR
    do_table_structure=True,        # Reconnaissance de tables
    artifacts_path="/path/to/models" # Mod√®les locaux
)

converter = DocumentConverter(
    format_options={
        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
    }
)

result = converter.convert("document.pdf")
```

### Options de Structure de Tables

#### Mode de Cell Matching

```python
from docling.datamodel.pipeline_options import PdfPipelineOptions

pipeline_options = PdfPipelineOptions(do_table_structure=True)

# D√©sactiver cell matching pour utiliser les cellules pr√©dites par le mod√®le
pipeline_options.table_structure_options.do_cell_matching = False

# Cr√©er le convertisseur avec ces options
converter = DocumentConverter(
    format_options={
        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
    }
)
```

#### Mode TableFormer (depuis v1.16.0)

```python
from docling.datamodel.pipeline_options import TableFormerMode

pipeline_options = PdfPipelineOptions(do_table_structure=True)

# Mode FAST: Plus rapide mais moins pr√©cis
pipeline_options.table_structure_options.mode = TableFormerMode.FAST

# Mode ACCURATE: Plus lent mais meilleure qualit√© (d√©faut)
pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE
```

### Limites de Taille et Pages

```python
from docling.document_converter import DocumentConverter

converter = DocumentConverter()

# Limiter √† 100 pages et 20MB
result = converter.convert(
    "large_document.pdf",
    max_num_pages=100,
    max_file_size=20971520  # 20MB en octets
)
```

### Services Distants (Opt-in Explicite)

```python
from docling.datamodel.pipeline_options import PdfPipelineOptions

# ATTENTION: Active la communication avec services externes
pipeline_options = PdfPipelineOptions(enable_remote_services=True)

converter = DocumentConverter(
    format_options={
        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
    }
)
```

**Services requ√©rant `enable_remote_services=True`**:
- `PictureDescriptionApiOptions`: Vision models via API

### Utilisation de Backends Sp√©cifiques

```python
import urllib.request
from io import BytesIO
from docling.backend.html_backend import HTMLDocumentBackend
from docling.datamodel.base_models import InputFormat, InputDocument

url = "https://en.wikipedia.org/wiki/Artificial_intelligence"
html_content = urllib.request.urlopen(url).read()

in_doc = InputDocument(
    path_or_stream=BytesIO(html_content),
    format=InputFormat.HTML,
    backend=HTMLDocumentBackend,
    filename="ai_article.html",
)

backend = HTMLDocumentBackend(in_doc=in_doc, path_or_stream=BytesIO(html_content))
docling_doc = backend.convert()

print(docling_doc.export_to_markdown())
```

---

## Formats Support√©s

### Formats d'Entr√©e

| Format | Extension | Notes |
|--------|-----------|-------|
| PDF | `.pdf` | Support complet avec analyse avanc√©e |
| Word | `.docx` | Microsoft Word 2007+ |
| PowerPoint | `.pptx` | Pr√©sentations |
| Excel | `.xlsx`, `.xls` | Feuilles de calcul |
| HTML | `.html`, `.htm` | Pages web |
| Images | `.png`, `.jpg`, `.jpeg`, `.tiff`, `.gif`, `.bmp`, `.webp` | Avec OCR |
| Audio | `.wav`, `.mp3`, `.m4a`, `.ogg`, `.flac` | Via ASR |
| Markdown | `.md` | Documents markdown |
| AsciiDoc | `.asciidoc`, `.adoc` | Documentation technique |

### Formats d'Exportation

| Format | M√©thode | Description |
|--------|---------|-------------|
| Markdown | `export_to_markdown()` | Format markdown standard |
| HTML | `export_to_html()` | HTML structur√© |
| JSON | `export_to_dict()` | Repr√©sentation compl√®te |
| DocTags | `export_to_doctags()` | Format DocTags (arXiv:2503.11576) |
| Plain Text | `export_to_text()` | Texte brut |

**Documentation formats**: https://docling-project.github.io/docling/usage/supported_formats/

---

## Exportation et Transformation

### Export Markdown

```python
# Standard
markdown = result.document.export_to_markdown()

# Avec options
markdown = result.document.export_to_markdown(
    include_metadata=True,
    strict_text=False
)
```

### Export HTML

```python
html = result.document.export_to_html()
```

### Export JSON (Lossless)

```python
# Dictionnaire Python
doc_dict = result.document.export_to_dict()

# JSON string
import json
json_str = json.dumps(doc_dict, indent=2)
```

### Export DocTags

```python
doctags = result.document.export_to_doctags()
```

**DocTags Reference**: https://arxiv.org/abs/2503.11576

### Acc√®s Programmatique aux √âl√©ments

```python
doc = result.document

# It√©rer sur tous les √©l√©ments
for item in doc.iterate_items():
    print(f"Type: {item.label}, Text: {item.text}")

# Acc√®s aux tables
for table in doc.tables:
    print(table.export_to_markdown())

# Acc√®s aux images
for picture in doc.pictures:
    print(f"Image: {picture.prov[0].bbox}")  # Bounding box

# Acc√®s aux m√©tadonn√©es
metadata = doc.metadata
print(f"Title: {metadata.title}")
print(f"Authors: {metadata.authors}")
```

---

## Int√©grations avec Frameworks IA

### LangChain

```python
from langchain_community.document_loaders import DoclingLoader

# Chargement avec DoclingLoader
loader = DoclingLoader(
    file_path="document.pdf",
    export_type="markdown"  # ou "text", "doctags"
)

documents = loader.load()

# Utiliser dans une cha√Æne RAG
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)
splits = text_splitter.split_documents(documents)

vectorstore = FAISS.from_documents(splits, OpenAIEmbeddings())
```

**Documentation**: https://python.langchain.com/docs/integrations/document_loaders/docling

### LlamaIndex

```python
from llama_index.core import SimpleDirectoryReader
from llama_index.readers.docling import DoclingReader

# Option 1: Via SimpleDirectoryReader
reader = SimpleDirectoryReader(
    input_files=["document.pdf"],
    file_extractor={".pdf": DoclingReader()}
)
documents = reader.load_data()

# Option 2: DoclingReader direct
docling_reader = DoclingReader()
documents = docling_reader.load_data(file_path="document.pdf")

# Cr√©er un index
from llama_index.core import VectorStoreIndex

index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()
response = query_engine.query("What is this document about?")
```

**Documentation**: https://docs.llamaindex.ai/en/stable/examples/data_connectors/DoclingReaderDemo/

### Haystack

```python
from haystack_integrations.components.converters.docling import DoclingConverter
from haystack import Pipeline

# Cr√©er le convertisseur
converter = DoclingConverter()

# Dans un pipeline
pipeline = Pipeline()
pipeline.add_component("converter", converter)

# Ex√©cuter
result = pipeline.run({
    "converter": {
        "sources": ["document.pdf"]
    }
})

documents = result["converter"]["documents"]
```

### Crew AI

```python
from crewai import Agent, Task, Crew
from docling.document_converter import DocumentConverter

# Convertir le document
converter = DocumentConverter()
result = converter.convert("research_paper.pdf")
markdown = result.document.export_to_markdown()

# Cr√©er un agent avec le contenu
researcher = Agent(
    role="Research Analyst",
    goal="Analyze research papers",
    backstory="Expert in scientific literature",
    verbose=True
)

task = Task(
    description=f"Analyze this research paper:\n\n{markdown}",
    agent=researcher
)

crew = Crew(agents=[researcher], tasks=[task])
result = crew.kickoff()
```

**Page int√©grations**: https://docling-project.github.io/docling/integrations/

---

## Chunking pour RAG

### HybridChunker

Le `HybridChunker` combine chunking bas√© sur la structure du document et sur les tokens.

```python
from docling.document_converter import DocumentConverter
from docling.chunking import HybridChunker

# Convertir document
converter = DocumentConverter()
result = converter.convert("document.pdf")
doc = result.document

# Cr√©er le chunker
chunker = HybridChunker(
    tokenizer="BAAI/bge-small-en-v1.5",  # Sp√©cifier le tokenizer
    max_tokens=512,                       # Taille max des chunks
    min_tokens=64,                        # Taille min des chunks
    merge_peers=True                      # Fusionner les √©l√©ments pairs
)

# Chunker le document
chunks = list(chunker.chunk(doc))

# Structure d'un chunk
for chunk in chunks[:3]:
    print("=" * 80)
    print(f"Text: {chunk['text'][:100]}...")
    print(f"Meta: {chunk['meta']}")
```

### Structure d'un Chunk

```python
{
    "text": "Full text of the chunk...",
    "meta": {
        "doc_items": [
            {
                "self_ref": "#/texts/28",
                "label": "text",
                "prov": [{
                    "page_no": 2,
                    "bbox": {
                        "l": 53.29, 
                        "t": 287.14, 
                        "r": 295.56, 
                        "b": 212.37
                    }
                }]
            }
        ],
        "headings": ["1 INTRODUCTION"],
        "origin": {
            "mimetype": "application/pdf",
            "filename": "document.pdf"
        }
    }
}
```

### Exemple RAG Complet

```python
from docling.document_converter import DocumentConverter
from docling.chunking import HybridChunker
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import Anthropic
from langchain.chains import RetrievalQA

# 1. Convertir documents
converter = DocumentConverter()
docs = []
for pdf_path in ["doc1.pdf", "doc2.pdf", "doc3.pdf"]:
    result = converter.convert(pdf_path)
    docs.append(result.document)

# 2. Chunker tous les documents
chunker = HybridChunker(tokenizer="BAAI/bge-small-en-v1.5")
all_chunks = []
for doc in docs:
    chunks = list(chunker.chunk(doc))
    all_chunks.extend(chunks)

# 3. Cr√©er embeddings et vectorstore
embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")

texts = [chunk['text'] for chunk in all_chunks]
metadatas = [chunk['meta'] for chunk in all_chunks]

vectorstore = FAISS.from_texts(texts, embeddings, metadatas=metadatas)

# 4. Cr√©er cha√Æne QA
llm = Anthropic(model="claude-sonnet-4-5-20250929")
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 5}),
    return_source_documents=True
)

# 5. Requ√™ter
response = qa_chain("What are the main findings of these documents?")
print(response["result"])
```

**Exemple d√©taill√©**: https://docling-project.github.io/docling/examples/hybrid_chunking/

---

## Gestion des Ressources et Performance

### Limitation CPU

```bash
# Limiter √† 2 threads CPU
export OMP_NUM_THREADS=2

# Ou dans le code (avant import)
import os
os.environ['OMP_NUM_THREADS'] = '2'

from docling.document_converter import DocumentConverter
```

### Limitation M√©moire

```python
# Traiter par batch avec lib√©ration m√©moire
import gc
from docling.document_converter import DocumentConverter

converter = DocumentConverter()
batch_size = 10

for i in range(0, len(document_list), batch_size):
    batch = document_list[i:i+batch_size]
    
    for doc_path in batch:
        result = converter.convert(doc_path)
        # Traiter le r√©sultat
        process_result(result)
    
    # Lib√©rer la m√©moire
    gc.collect()
```

### Optimisation Pipeline

```python
from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode

# Pour rapidit√© maximale
fast_pipeline = PdfPipelineOptions(
    do_ocr=False,  # D√©sactiver OCR si pas n√©cessaire
    do_table_structure=True,
)
fast_pipeline.table_structure_options.mode = TableFormerMode.FAST

# Pour qualit√© maximale
accurate_pipeline = PdfPipelineOptions(
    do_ocr=True,
    do_table_structure=True,
)
accurate_pipeline.table_structure_options.mode = TableFormerMode.ACCURATE
```

### Parall√©lisation

```python
from concurrent.futures import ThreadPoolExecutor
from docling.document_converter import DocumentConverter

def convert_document(doc_path):
    converter = DocumentConverter()
    return converter.convert(doc_path)

# Traiter en parall√®le (attention √† la m√©moire)
with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(convert_document, document_paths))
```

### Monitoring Performance

```python
import time
from docling.document_converter import DocumentConverter

converter = DocumentConverter()

start = time.time()
result = converter.convert("document.pdf")
duration = time.time() - start

print(f"Conversion time: {duration:.2f}s")
print(f"Pages: {len(result.document.pages)}")
print(f"Time per page: {duration/len(result.document.pages):.2f}s")
```

---

## Bonnes Pratiques pour Agents IA

### 1. Gestion d'Erreurs Robuste

```python
from docling.document_converter import DocumentConverter
from docling.exceptions import ConversionError

def safe_convert(doc_path):
    """Conversion s√©curis√©e avec gestion d'erreurs."""
    try:
        converter = DocumentConverter()
        result = converter.convert(
            doc_path,
            max_num_pages=500,      # Limite de s√©curit√©
            max_file_size=50*1024*1024  # 50MB max
        )
        return result.document, None
    except ConversionError as e:
        return None, f"Conversion error: {str(e)}"
    except Exception as e:
        return None, f"Unexpected error: {str(e)}"

# Utilisation
doc, error = safe_convert("document.pdf")
if error:
    print(f"Failed to convert: {error}")
else:
    markdown = doc.export_to_markdown()
```

### 2. Validation des Entr√©es

```python
from pathlib import Path
import mimetypes

def validate_document(file_path):
    """Valider que le fichier est support√©."""
    path = Path(file_path)
    
    if not path.exists():
        return False, "File does not exist"
    
    if not path.is_file():
        return False, "Path is not a file"
    
    # V√©rifier extension
    supported_extensions = {
        '.pdf', '.docx', '.pptx', '.xlsx', 
        '.html', '.htm', '.md', '.png', 
        '.jpg', '.jpeg', '.tiff', '.wav', '.mp3'
    }
    
    if path.suffix.lower() not in supported_extensions:
        return False, f"Unsupported format: {path.suffix}"
    
    return True, "Valid"

# Utilisation
is_valid, message = validate_document("document.pdf")
if not is_valid:
    print(f"Validation failed: {message}")
```

### 3. Extraction d'Informations Structur√©es

```python
def extract_structured_data(doc):
    """Extraire donn√©es structur√©es d'un DoclingDocument."""
    data = {
        "metadata": {
            "title": doc.metadata.title,
            "authors": doc.metadata.authors,
            "language": doc.metadata.language,
        },
        "statistics": {
            "num_pages": len(doc.pages),
            "num_tables": len(doc.tables),
            "num_pictures": len(doc.pictures),
        },
        "tables": [],
        "sections": []
    }
    
    # Extraire tables
    for table in doc.tables:
        data["tables"].append({
            "markdown": table.export_to_markdown(),
            "page": table.prov[0].page_no if table.prov else None
        })
    
    # Extraire structure des sections
    current_section = None
    for item in doc.iterate_items():
        if item.label == "section_header":
            current_section = {
                "title": item.text,
                "level": item.level,
                "content": []
            }
            data["sections"].append(current_section)
        elif current_section and item.label == "text":
            current_section["content"].append(item.text)
    
    return data
```

### 4. Cache pour Performance

```python
import hashlib
import pickle
from pathlib import Path

class DocumentCache:
    """Cache simple pour conversions."""
    
    def __init__(self, cache_dir=".docling_cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def _get_cache_key(self, file_path):
        """G√©n√©rer cl√© de cache bas√©e sur hash du fichier."""
        with open(file_path, 'rb') as f:
            file_hash = hashlib.md5(f.read()).hexdigest()
        return f"{Path(file_path).stem}_{file_hash}.pkl"
    
    def get(self, file_path):
        """R√©cup√©rer du cache."""
        cache_file = self.cache_dir / self._get_cache_key(file_path)
        if cache_file.exists():
            with open(cache_file, 'rb') as f:
                return pickle.load(f)
        return None
    
    def set(self, file_path, doc):
        """Sauvegarder dans cache."""
        cache_file = self.cache_dir / self._get_cache_key(file_path)
        with open(cache_file, 'wb') as f:
            pickle.dump(doc, f)

# Utilisation
cache = DocumentCache()
converter = DocumentConverter()

doc = cache.get("document.pdf")
if doc is None:
    result = converter.convert("document.pdf")
    doc = result.document
    cache.set("document.pdf", doc)

markdown = doc.export_to_markdown()
```

### 5. Logging D√©taill√©

```python
import logging
from datetime import datetime

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('docling_agent')

def convert_with_logging(doc_path):
    """Conversion avec logging d√©taill√©."""
    logger.info(f"Starting conversion of {doc_path}")
    start_time = datetime.now()
    
    try:
        converter = DocumentConverter()
        result = converter.convert(doc_path)
        
        duration = (datetime.now() - start_time).total_seconds()
        logger.info(f"Conversion successful in {duration:.2f}s")
        logger.info(f"Pages: {len(result.document.pages)}")
        logger.info(f"Tables: {len(result.document.tables)}")
        
        return result.document
        
    except Exception as e:
        logger.error(f"Conversion failed: {str(e)}", exc_info=True)
        raise
```

### 6. Workflow Typique pour Agent IA

```python
from docling.document_converter import DocumentConverter
from docling.chunking import HybridChunker

class DocumentProcessor:
    """Processeur de documents pour agent IA."""
    
    def __init__(self):
        self.converter = DocumentConverter()
        self.chunker = HybridChunker(tokenizer="BAAI/bge-small-en-v1.5")
    
    def process_document(self, doc_path, output_format="markdown"):
        """
        Traiter un document complet.
        
        Args:
            doc_path: Chemin vers le document
            output_format: Format de sortie ('markdown', 'json', 'chunks')
        
        Returns:
            dict avec r√©sultats du traitement
        """
        # 1. Validation
        is_valid, msg = validate_document(doc_path)
        if not is_valid:
            return {"error": msg}
        
        # 2. Conversion
        try:
            result = self.converter.convert(doc_path)
            doc = result.document
        except Exception as e:
            return {"error": f"Conversion failed: {str(e)}"}
        
        # 3. Extraction selon format
        if output_format == "markdown":
            return {
                "content": doc.export_to_markdown(),
                "metadata": self._extract_metadata(doc)
            }
        
        elif output_format == "json":
            return {
                "content": doc.export_to_dict(),
                "metadata": self._extract_metadata(doc)
            }
        
        elif output_format == "chunks":
            chunks = list(self.chunker.chunk(doc))
            return {
                "chunks": chunks,
                "metadata": self._extract_metadata(doc),
                "num_chunks": len(chunks)
            }
    
    def _extract_metadata(self, doc):
        """Extraire m√©tadonn√©es utiles."""
        return {
            "title": doc.metadata.title,
            "num_pages": len(doc.pages),
            "num_tables": len(doc.tables),
            "num_images": len(doc.pictures),
        }

# Utilisation
processor = DocumentProcessor()
result = processor.process_document("research.pdf", output_format="chunks")

if "error" not in result:
    print(f"Processed {result['num_chunks']} chunks")
    print(f"Title: {result['metadata']['title']}")
```

---

## R√©solution de Probl√®mes

### Probl√®mes Courants

#### 1. Mod√®les Non T√©l√©charg√©s

**Sympt√¥me**: Erreur de mod√®le manquant lors de la premi√®re utilisation

**Solution**:
```bash
docling-tools models download
```

#### 2. M√©moire Insuffisante

**Sympt√¥me**: `MemoryError` ou crash lors du traitement de gros documents

**Solutions**:
```python
# Limiter le nombre de pages
result = converter.convert(doc, max_num_pages=100)

# Limiter la taille du fichier
result = converter.convert(doc, max_file_size=20*1024*1024)  # 20MB

# R√©duire les threads
os.environ['OMP_NUM_THREADS'] = '2'
```

#### 3. OCR Lent

**Sympt√¥me**: Conversion de PDFs scann√©s tr√®s lente

**Solutions**:
```python
# D√©sactiver OCR si pas n√©cessaire
pipeline_options = PdfPipelineOptions(do_ocr=False)

# Ou r√©duire la r√©solution d'OCR
pipeline_options = PdfPipelineOptions(do_ocr=True)
pipeline_options.ocr_options.resolution = 200  # DPI plus bas
```

#### 4. Tables Mal Extraites

**Sympt√¥me**: Structure de tables incorrecte

**Solutions**:
```python
# Essayer sans cell matching
pipeline_options = PdfPipelineOptions(do_table_structure=True)
pipeline_options.table_structure_options.do_cell_matching = False

# Ou utiliser mode ACCURATE
from docling.datamodel.pipeline_options import TableFormerMode
pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE
```

#### 5. Erreur de Permissions

**Sympt√¥me**: `OperationNotAllowed` lors de l'utilisation de services distants

**Solution**:
```python
# Activer explicitement les services distants
pipeline_options = PdfPipelineOptions(enable_remote_services=True)
```

### D√©bogage

```python
import logging

# Activer logging d√©taill√©
logging.basicConfig(level=logging.DEBUG)

# Pour Docling sp√©cifiquement
logging.getLogger('docling').setLevel(logging.DEBUG)
```

### Support et Communaut√©

- **GitHub Issues**: https://github.com/docling-project/docling/issues
- **Discussions**: https://github.com/docling-project/docling/discussions
- **Dosu AI Assistant**: https://app.dosu.dev/097760a8-135e-4789-8234-90c8837d7f1c/ask

---

## Ressources et R√©f√©rences

### Documentation Officielle

- **Site Principal**: https://docling-project.github.io/docling/
- **GitHub Repository**: https://github.com/docling-project/docling
- **Installation Guide**: https://docling-project.github.io/docling/installation/
- **Usage Guide**: https://docling-project.github.io/docling/usage/
- **Examples**: https://docling-project.github.io/docling/examples/
- **API Reference**: https://docling-project.github.io/docling/reference/document_converter/
- **CLI Reference**: https://docling-project.github.io/docling/reference/cli/

### Articles et Papers

- **Docling Technical Report**: https://arxiv.org/abs/2408.09869
  - Citation: Deep Search Team. "Docling Technical Report." arXiv:2408.09869, 2024.
- **DocTags Format**: https://arxiv.org/abs/2503.11576
- **DocLayNet Dataset**: https://arxiv.org/abs/2206.01062
- **TableFormer**: Rechercher sur arXiv pour d√©tails sur le mod√®le

### Mod√®les et Datasets

- **SmolDocling on Hugging Face**: https://huggingface.co/ds4sd/SmolDocling-256M-preview
- **DocLayNet**: Layout analysis model
- **TableFormer**: Table structure recognition model

### Int√©grations

- **LangChain**: https://python.langchain.com/docs/integrations/document_loaders/docling
- **LlamaIndex**: https://docs.llamaindex.ai/en/stable/examples/data_connectors/DoclingReaderDemo/
- **Haystack**: https://haystack.deepset.ai/integrations/docling
- **Crew AI**: Documentation sur site Crew AI

### Communaut√© et Support

- **LF AI & Data Foundation**: https://lfaidata.foundation/projects/
- **Contributing Guide**: https://github.com/docling-project/docling/blob/main/CONTRIBUTING.md
- **License**: MIT License

### Exemples de Code

Repository d'exemples: https://docling-project.github.io/docling/examples/

Exemples importants:
- **Basic Conversion**: Conversion simple de documents
- **Custom Convert**: Configuration avanc√©e du pipeline
- **Hybrid Chunking**: Chunking pour RAG
- **Multi-format Conversion**: Traiter plusieurs formats
- **Batch Processing**: Traitement en batch
- **RAG Integration**: Int√©gration avec syst√®mes RAG

### Outils Utiles

- **docling-tools**: Utilitaires CLI pour gestion des mod√®les
  ```bash
  docling-tools models download
  docling-tools models list
  ```

### Changelog et Versions

- **Derni√®re version stable**: V√©rifier sur PyPI ou GitHub releases
- **Changelog**: https://github.com/docling-project/docling/releases
- **Breaking Changes**: Suivre les notes de release pour migrations

---

## Citation

Si vous utilisez Docling dans votre travail, veuillez citer:

```bibtex
@techreport{Docling,
  author = {Deep Search Team},
  month = {8},
  title = {Docling Technical Report},
  url = {https://arxiv.org/abs/2408.09869},
  eprint = {2408.09869},
  doi = {10.48550/arXiv.2408.09869},
  version = {1.0.0},
  year = {2024}
}
```

---

## Notes pour Agent IA Claude Sonnet 4.5

### Points Critiques √† Retenir

1. **Toujours valider les entr√©es** avant conversion
2. **G√©rer les erreurs robustement** - la conversion peut √©chouer
3. **Optimiser pour le cas d'usage** - d√©sactiver fonctionnalit√©s non n√©cessaires
4. **Utiliser le chunking** pour int√©grations RAG
5. **Cache les r√©sultats** pour documents fr√©quemment acc√©d√©s
6. **Monitor la m√©moire** pour gros documents
7. **Logger les op√©rations** pour d√©bogage
8. **Tester avec diff√©rents formats** - chaque format a ses sp√©cificit√©s

### Workflow Recommand√©

```
1. Validation du document
   ‚Üì
2. Conversion avec gestion d'erreurs
   ‚Üì
3. Extraction/transformation selon besoin
   ‚Üì
4. Export dans format appropri√©
   ‚Üì
5. Post-traitement si n√©cessaire
```

### Quand Utiliser Docling

‚úÖ **Utiliser pour**:
- Extraction de contenu PDF structur√©
- Conversion multi-format vers format unifi√©
- Pr√©paration de documents pour RAG
- Analyse de structure de documents
- Extraction de tables et m√©tadonn√©es

‚ùå **Ne pas utiliser pour**:
- Simple lecture de texte brut
- √âdition de documents (pas d'√©dition, seulement lecture)
- G√©n√©ration de documents (seulement parsing)
- Traitement en temps r√©el ultra-rapide (privil√©gier cache)

---

**Document g√©n√©r√© le**: 27 octobre 2025  
**Version Docling couverte**: 1.16.0+  
**Licence**: Ce guide est fourni "as-is" pour usage avec Docling (MIT License)