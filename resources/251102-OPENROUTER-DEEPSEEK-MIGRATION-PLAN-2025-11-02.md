# ğŸ”„ MIGRATION PLAN: Haiku 4.5 â†’ OpenRouter DeepSeek R1 (FREE)

**Date:** Nov 2, 2025, 17:00 CET  
**Version:** Migration Plan v1.0  
**Status:** ğŸ“‹ PLAN COMPLET - Ready for execution

---

## ğŸ¯ OBJECTIF

**Migrer le Knowledge Graph ARIA de Claude Haiku 4.5 (coÃ»teux) vers DeepSeek R1 (gratuit via OpenRouter)**

### StratÃ©gie

| SystÃ¨me | Provider | ModÃ¨le | CoÃ»t | Statut |
|---------|----------|--------|------|--------|
| **Agents** (ARIA, CARO, BOB, etc.) | Anthropic Direct | Sonnet 4.5 | $3/$15/M tokens | âœ… **INCHANGÃ‰** |
| **Knowledge Graph** (Graphiti) | OpenRouter | DeepSeek R1 Free | **$0** | ğŸ”„ **Ã€ MIGRER** |

**Raison:** Le Knowledge Graph avec Haiku 4.5 coÃ»te trop cher (~$1-2/nuit minimum), mÃªme aprÃ¨s optimisation. DeepSeek R1 via OpenRouter est **gratuit** et suffisant pour entity extraction.

---

## ğŸ“Š AUDIT COMPLET

### âœ… ClÃ©s API Disponibles

**VÃ©rifiÃ© dans `.aria/.env` :**
```bash
OPENAI_API_KEY=sk-proj-...        # âœ… PrÃ©sent (embeddings)
ANTHROPIC_API_KEY=sk-ant-api03-...# âœ… PrÃ©sent (agents)
OPENROUTER_API_KEY=sk-or-v1-...   # âœ… PrÃ©sent (nouveau!)
```

### ğŸ“ Fichiers IdentifiÃ©s pour Migration

**1. Code Principal (2 fichiers) :**
- `.aria/knowledge/ingestion/ingest_to_graphiti.py` (lignes 20-162)
  - Import `AnthropicClient` â†’ `OpenAIGenericClient`
  - Configuration Haiku 4.5 â†’ DeepSeek R1 + OpenRouter
  - Monkey-patch Anthropic metadata â†’ Ã€ retirer (non applicable)
  - Print messages â†’ Mettre Ã  jour

**2. Tests (2 fichiers) :**
- `.aria/knowledge/tests/test_anthropic_graphiti.py`
  - Renommer en `test_deepseek_graphiti.py`
  - Adapter configuration
- `.aria/knowledge/tests/test_haiku_ingestion.py`
  - Adapter ou renommer

**3. MCP Server (1 fichier) :**
- `.aria/knowledge/mcp_servers/graphiti_mcp_server.py`
  - Aucun changement nÃ©cessaire (utilise `GraphitiIngestion()`)

**4. Docker (1 fichier) :**
- `.aria/knowledge/zep/docker-compose.yml`
  - Ligne 28: `ZEP_LLM_SERVICE=anthropic` â†’ Peut rester (service Zep indÃ©pendant)
  - Ligne 54: `ANTHROPIC_API_KEY` â†’ Peut rester (pour Zep)

**5. Configuration MCP (1 fichier) :**
- `.aria/knowledge/mcp_servers/aria-graphiti-mcp-config.json`
  - Ligne 10: `ANTHROPIC_API_KEY` exposÃ©e â†’ Mettre `OPENROUTER_API_KEY`

**6. Documentation (1 fichier principal) :**
- `.aria/knowledge/README.md`
  - Mettre Ã  jour "Architecture" (ligne 6, 119-130)
  - Mettre Ã  jour "LLM Provider" (ligne 7)

### ğŸ” CompatibilitÃ© Graphiti

**âœ… Graphiti supporte OpenRouter via `OpenAIGenericClient` !**

**Preuve :**
```python
from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient
from graphiti_core.llm_client import LLMConfig

config = LLMConfig(
    api_key="sk-or-v1-...",          # OpenRouter API key
    base_url="https://openrouter.ai/api/v1",  # Custom base URL
    model="deepseek/deepseek-r1:free",
    max_tokens=2048,
    temperature=0.0
)
client = OpenAIGenericClient(config=config)
```

**Avantages :**
- âœ… Compatible API OpenAI (OpenRouter suit le standard)
- âœ… Support `base_url` custom
- âœ… Pas de monkey-patch nÃ©cessaire
- âœ… Plus simple que AnthropicClient

---

## ğŸ”§ PLAN DE MIGRATION DÃ‰TAILLÃ‰

### Phase 1: Backup (5 min)

**Actions :**
1. CrÃ©er backup du code actuel
   ```bash
   mkdir -p .aria/backups/2025-11-02-pre-openrouter
   cp .aria/knowledge/ingestion/ingest_to_graphiti.py .aria/backups/2025-11-02-pre-openrouter/
   cp .aria/knowledge/README.md .aria/backups/2025-11-02-pre-openrouter/
   ```

2. Commit Ã©tat actuel (si nÃ©cessaire)
   ```bash
   git add -A
   git commit -m "backup: Before OpenRouter DeepSeek R1 migration"
   ```

**Validation :**
- âœ… Backups crÃ©Ã©s
- âœ… Git propre

---

### Phase 2: Mise Ã  jour Code Principal (20 min)

**Fichier:** `.aria/knowledge/ingestion/ingest_to_graphiti.py`

#### 2.1. Imports (lignes 20-24)

**AVANT:**
```python
from graphiti_core.llm_client.anthropic_client import AnthropicClient
import sentry_sdk
from sentry_sdk.integrations.anthropic import AnthropicIntegration
```

**APRÃˆS:**
```python
from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient
import sentry_sdk
# Anthropic integration removed (not needed for OpenRouter)
```

#### 2.2. Docstring Classe (ligne 37)

**AVANT:**
```python
"""Ingest reports into Graphiti knowledge graph using Claude Haiku 4.5."""
```

**APRÃˆS:**
```python
"""Ingest reports into Graphiti knowledge graph using DeepSeek R1 (via OpenRouter)."""
```

#### 2.3. ParamÃ¨tre __init__ (ligne 44)

**AVANT:**
```python
use_anthropic: bool = True  # NEW: Use Claude Haiku 4.5 by default
```

**APRÃˆS:**
```python
use_openrouter: bool = True  # NEW: Use DeepSeek R1 via OpenRouter by default
```

#### 2.4. MÃ©thode initialize() (lignes 63-115)

**AVANT:**
```python
async def initialize(self):
    """Initialize Graphiti client with Claude Haiku 4.5 (async)."""
    if self.graphiti is None:
        # Configure LLM client with metadata support
        llm_client = None
        if self.use_anthropic:
            # Use Claude Haiku 4.5 for LLM operations
            anthropic_key = os.getenv('ANTHROPIC_API_KEY')
            if not anthropic_key:
                raise ValueError("ANTHROPIC_API_KEY not found in environment")
            
            llm_config = LLMConfig(
                api_key=anthropic_key,
                model='claude-haiku-4-5-20251001',  # Haiku 4.5 official model ID
                max_tokens=2048,       # Production Guide Line 351
                temperature=0.0        # Production Guide Line 352
            )
            llm_client = AnthropicClient(config=llm_config, cache=False)
            
            # â­ MONKEY-PATCH: Inject metadata into Anthropic API calls
            self._patch_anthropic_client(llm_client)
            
            print("ğŸ¤– Using Claude Haiku 4.5 for LLM operations (v1.5.0)")
            print("ğŸ“Š Anthropic Usage API tracking enabled (metadata injection)")
        else:
            print("ğŸ¤– Using OpenAI (default) for LLM operations")
```

**APRÃˆS:**
```python
async def initialize(self):
    """Initialize Graphiti client with DeepSeek R1 via OpenRouter (async)."""
    if self.graphiti is None:
        # Configure LLM client
        llm_client = None
        if self.use_openrouter:
            # Use DeepSeek R1 (FREE) via OpenRouter for LLM operations
            openrouter_key = os.getenv('OPENROUTER_API_KEY')
            if not openrouter_key:
                raise ValueError("OPENROUTER_API_KEY not found in environment")
            
            llm_config = LLMConfig(
                api_key=openrouter_key,
                base_url="https://openrouter.ai/api/v1",  # OpenRouter endpoint
                model='deepseek/deepseek-r1:free',        # DeepSeek R1 FREE model
                max_tokens=2048,       # Keep same config (Production Guide)
                temperature=0.0        # Deterministic extraction
            )
            llm_client = OpenAIGenericClient(config=llm_config, cache=False)
            
            print("ğŸ¤– Using DeepSeek R1 for LLM operations (via OpenRouter) - FREE! ğŸ‰")
            print("ğŸ’° Cost: $0/night (was $1-2 with Haiku 4.5)")
            print("ğŸŒ Provider: OpenRouter (https://openrouter.ai)")
        else:
            print("ğŸ¤– Using OpenAI (default) for LLM operations")
```

#### 2.5. SEMAPHORE_LIMIT (lignes 90-102)

**AVANT:**
```python
# Set SEMAPHORE_LIMIT based on production guide recommendations (Priority 4B)
# Production Guide Line 337-341:
# - Default: 10 (safe for most providers)
# - Anthropic Claude: 15-20 (higher rate limits)
# - Lower to 5-8 only if hitting 429 errors
#
# RECOMMENDATION: Set SEMAPHORE_LIMIT=15 in .env for optimal throughput
# Default to 15 if not set (Anthropic handles this well)
if not os.getenv('SEMAPHORE_LIMIT'):
    os.environ['SEMAPHORE_LIMIT'] = '15'
    print("ğŸ”§ Set SEMAPHORE_LIMIT=15 (default for Anthropic Claude)")
else:
    print(f"ğŸ”§ SEMAPHORE_LIMIT={os.getenv('SEMAPHORE_LIMIT')} (from .env)")
```

**APRÃˆS:**
```python
# Set SEMAPHORE_LIMIT for OpenRouter DeepSeek R1
# OpenRouter free tier has rate limits, so we use conservative value
# - DeepSeek R1 Free: Start with 5 concurrent calls
# - Can increase to 8-10 if no 429 errors observed
# - Lower to 3 if hitting rate limits
#
# RECOMMENDATION: Set SEMAPHORE_LIMIT=5 in .env for free tier
# Default to 5 if not set (conservative for free tier)
if not os.getenv('SEMAPHORE_LIMIT'):
    os.environ['SEMAPHORE_LIMIT'] = '5'
    print("ğŸ”§ Set SEMAPHORE_LIMIT=5 (default for OpenRouter free tier)")
else:
    print(f"ğŸ”§ SEMAPHORE_LIMIT={os.getenv('SEMAPHORE_LIMIT')} (from .env)")
```

#### 2.6. Print Message (ligne 115)

**AVANT:**
```python
print("âœ… Graphiti initialized (LLM: Claude Haiku 4.5, Embeddings: OpenAI)")
```

**APRÃˆS:**
```python
print("âœ… Graphiti initialized (LLM: DeepSeek R1 FREE via OpenRouter, Embeddings: OpenAI)")
```

#### 2.7. Retirer Monkey-Patch (lignes 117-162)

**AVANT:**
```python
def _patch_anthropic_client(self, client: AnthropicClient):
    """
    Monkey-patch Anthropic client to inject metadata into API calls.
    ... (60 lignes)
    """
    # ... code complet ...
```

**APRÃˆS:**
```python
# Monkey-patch removed - not needed for OpenRouter
# OpenRouter uses standard OpenAI API format (no metadata injection needed)
```

#### 2.8. MÃ©thode _build_description_metadata (ligne 164-197)

**AVANT:**
```python
def _build_description_metadata(self, report_data: Dict[str, Any]) -> str:
    """Build description for Anthropic Usage API tracking."""
    # ... code ...
```

**APRÃˆS:**
```python
# Metadata tracking removed - not applicable to OpenRouter free tier
# Cost is $0, so no need to track per-agent consumption
```

**Validation Phase 2 :**
- âœ… Imports mis Ã  jour
- âœ… Configuration OpenRouter implÃ©mentÃ©e
- âœ… Monkey-patch retirÃ©
- âœ… SEMAPHORE_LIMIT adaptÃ© (5)
- âœ… Messages mis Ã  jour

---

### Phase 3: Mise Ã  jour Tests (15 min)

#### 3.1. Renommer test principal

**Action:**
```bash
cd .aria/knowledge/tests
mv test_anthropic_graphiti.py test_deepseek_graphiti.py
```

#### 3.2. Adapter `test_deepseek_graphiti.py`

**Changements:**
- Import: `AnthropicClient` â†’ `OpenAIGenericClient`
- Variable: `ANTHROPIC_API_KEY` â†’ `OPENROUTER_API_KEY`
- Model: `claude-haiku-4-5-20251001` â†’ `deepseek/deepseek-r1:free`
- Config: Ajouter `base_url="https://openrouter.ai/api/v1"`
- Messages: Adapter les prints

#### 3.3. Adapter `test_haiku_ingestion.py`

**Option 1:** Renommer en `test_deepseek_ingestion.py` et adapter
**Option 2:** Laisser tel quel (test gÃ©nÃ©rique)

**Validation Phase 3 :**
- âœ… Tests renommÃ©s
- âœ… Configuration adaptÃ©e
- âœ… Tests prÃªts Ã  exÃ©cuter

---

### Phase 4: Configuration MCP (5 min)

**Fichier:** `.aria/knowledge/mcp_servers/aria-graphiti-mcp-config.json`

**AVANT (ligne 10):**
```json
"ANTHROPIC_API_KEY": "sk-ant-api03-..."
```

**APRÃˆS:**
```json
"OPENROUTER_API_KEY": "sk-or-v1-..."
```

**Note:** Le serveur MCP utilise `GraphitiIngestion()` qui lira automatiquement `OPENROUTER_API_KEY`.

**Validation Phase 4 :**
- âœ… MCP config mis Ã  jour

---

### Phase 5: Documentation (10 min)

**Fichier:** `.aria/knowledge/README.md`

#### 5.1. Header (lignes 1-11)

**AVANT:**
```markdown
**Architecture:** Graphiti + Neo4j Community Edition + **Claude Haiku 4.5** ğŸš€  
**LLM Provider:** **Claude Haiku 4.5** (near-frontier intelligence) âœ… IN PRODUCTION  
**Monitoring:** âœ… Sentry integrated  
**Rate Limit Protection:** âœ… Safe Ingestion Queue + Zero OpenAI LLM rate limits âœ…
```

**APRÃˆS:**
```markdown
**Architecture:** Graphiti + Neo4j Community Edition + **DeepSeek R1 (FREE via OpenRouter)** ğŸ’°  
**LLM Provider:** **DeepSeek R1** (via OpenRouter) - **$0 cost!** âœ… IN PRODUCTION  
**Monitoring:** âœ… Sentry integrated  
**Rate Limit Protection:** âœ… Safe Ingestion Queue + Conservative SEMAPHORE_LIMIT=5
```

#### 5.2. Key Features (lignes 18-32)

**AVANT:**
```markdown
- ğŸ¤– **Near-Frontier Intelligence** - Claude Haiku 4.5 = Sonnet 4 performance (v1.4.0) ğŸš€
- âš¡ **2Ã— Faster Processing** - Claude Haiku 4.5 speed advantage (v1.4.0)
- ğŸ’° **Cost Optimized** - $1/$5 per million tokens (v1.4.0)
```

**APRÃˆS:**
```markdown
- ğŸ¤– **Free Tier LLM** - DeepSeek R1 via OpenRouter (v1.7.0) ğŸ’°
- âš¡ **Zero Cost** - $0/night for knowledge graph operations! ğŸ‰
- ğŸ’° **Budget Friendly** - Free tier = unlimited nightly runs
```

#### 5.3. Technology Stack (lignes 118-131)

**AVANT:**
```markdown
### Technology Stack
- **Claude Haiku 4.5** - Near-frontier intelligence for LLM operations (v1.4.0) ğŸš€
  - Model: `claude-haiku-4-5-20251001`
  - Performance: Equals Sonnet 4 intelligence
  - Speed: 2Ã— faster than Sonnet 4
  - Cost: $1 input / $5 output per million tokens
```

**APRÃˆS:**
```markdown
### Technology Stack
- **DeepSeek R1** - Free tier LLM via OpenRouter (v1.7.0) ğŸ’°
  - Model: `deepseek/deepseek-r1:free`
  - Provider: OpenRouter (https://openrouter.ai)
  - Performance: Sufficient for entity extraction
  - Speed: Good for nightly batch processing
  - Cost: **$0** (free tier!)
```

#### 5.4. Version History (ligne 98)

**Ajouter:**
```markdown
- v1.7.0 (Nov 2): **MIGRATION TO OPENROUTER DEEPSEEK R1 (FREE)** ğŸ’°
  * BREAKING: Replaced Claude Haiku 4.5 with DeepSeek R1 via OpenRouter
  * Cost: $1-2/night â†’ **$0/night** (100% reduction!)
  * Reason: Knowledge Graph too expensive with Anthropic
  * Provider: OpenRouter (https://openrouter.ai)
  * Model: deepseek/deepseek-r1:free
  * Config: SEMAPHORE_LIMIT=5 (conservative for free tier)
  * Status: Agents still use Sonnet 4.5 (Anthropic direct)
  * Impact: Unlimited nightly runs, zero knowledge graph costs
```

**Validation Phase 5 :**
- âœ… README.md mis Ã  jour
- âœ… Version history complÃ©tÃ©
- âœ… Architecture documentÃ©e

---

### Phase 6: Variables d'Environnement (2 min)

**Fichier:** `.aria/.env`

**VÃ©rifier prÃ©sence de:**
```bash
OPENROUTER_API_KEY=sk-or-v1-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
```

**âš ï¸ SECURITY NOTE:** The actual API key was removed from this document for security reasons. Use the key from your `.env` file.

**Optionnel - Ajuster SEMAPHORE_LIMIT:**
```bash
# Add or update:
SEMAPHORE_LIMIT=5  # Conservative for OpenRouter free tier
```

**Validation Phase 6 :**
- âœ… OPENROUTER_API_KEY prÃ©sent
- âœ… SEMAPHORE_LIMIT configurÃ©

---

### Phase 7: Test Validation (20 min)

#### 7.1. Test Unitaire

```bash
cd .aria/knowledge/tests
pytest test_deepseek_graphiti.py -v
```

**Attendu:**
- âœ… Connexion OpenRouter rÃ©ussie
- âœ… Graphiti initialisÃ©
- âœ… Episode ingestÃ©
- âœ… Entity extraction fonctionnelle

#### 7.2. Test d'IntÃ©gration

```bash
cd .aria/knowledge/automation
python3 test_single_episode.py
```

**Attendu:**
- âœ… GraphitiIngestion initialisÃ© avec DeepSeek R1
- âœ… Episode ingestÃ© via OpenRouter
- âœ… CoÃ»t = $0
- âœ… Pas d'erreur 429

#### 7.3. Test Complet (Micro-Batch)

**CrÃ©er:** `.aria/knowledge/automation/test_deepseek_micro.py`
```python
"""Test DeepSeek R1 avec 3 micro episodes"""
import asyncio
from ingest_to_graphiti import GraphitiIngestion

async def test_deepseek_micro():
    print("ğŸ§ª Testing DeepSeek R1 via OpenRouter...")
    
    client = GraphitiIngestion(use_openrouter=True)
    await client.initialize()
    
    # Test 3 micro episodes
    for i in range(3):
        episode = {
            'name': f'test-deepseek-{i}',
            'episode_body': f'Test episode {i} for DeepSeek R1 validation.',
            'source_description': 'Test',
            'reference_time': '2025-11-02T17:00:00'
        }
        await client.ingest_report(episode)
        print(f"âœ… Episode {i} ingested")
    
    print("ğŸ‰ DeepSeek R1 validation complete!")

if __name__ == '__main__':
    asyncio.run(test_deepseek_micro())
```

**ExÃ©cuter:**
```bash
python3 .aria/knowledge/automation/test_deepseek_micro.py
```

**Attendu:**
- âœ… 3/3 episodes ingested
- âœ… Cost: $0
- âœ… No rate limit errors
- âœ… < 30 seconds execution

**Validation Phase 7 :**
- âœ… Tests unitaires passent
- âœ… Test intÃ©gration passe
- âœ… Micro-batch validÃ©
- âœ… CoÃ»t confirmÃ© $0

---

### Phase 8: Commit & Documentation (10 min)

#### 8.1. Commit Changes

```bash
cd /Users/nicozefrench/Obsidian

git add .aria/knowledge/ingestion/ingest_to_graphiti.py
git add .aria/knowledge/README.md
git add .aria/knowledge/tests/test_deepseek_graphiti.py
git add .aria/knowledge/mcp_servers/aria-graphiti-mcp-config.json
git add .aria/docs/deployment/OPENROUTER-DEEPSEEK-MIGRATION-PLAN-2025-11-02.md

git commit -m "feat: Migrate Knowledge Graph from Haiku 4.5 to DeepSeek R1 (OpenRouter FREE)

ğŸ”„ MAJOR MIGRATION: Knowledge Graph LLM Provider Change

Migrated ARIA Knowledge Graph from Claude Haiku 4.5 (Anthropic, costly)
to DeepSeek R1 via OpenRouter (FREE tier).

ğŸ¯ Motivation:
- Knowledge Graph with Haiku 4.5 costs \$1-2/night minimum (even optimized)
- DeepSeek R1 via OpenRouter is FREE
- Entity extraction doesn't require frontier intelligence
- Agents (ARIA, CARO, BOB, etc.) still use Sonnet 4.5 (Anthropic direct)

ğŸ’° Cost Impact:
- Before: \$1-2/night (Knowledge Graph alone)
- After: \$0/night (100% reduction!)
- Annual Savings: \$365-730 saved!

ğŸ”§ Changes:
- Replaced AnthropicClient with OpenAIGenericClient
- Updated model: claude-haiku-4-5-20251001 â†’ deepseek/deepseek-r1:free
- Added OpenRouter config: base_url, OPENROUTER_API_KEY
- Removed Anthropic metadata injection (not applicable)
- Updated SEMAPHORE_LIMIT: 15 â†’ 5 (conservative for free tier)
- Updated documentation: README.md, version history

ğŸ“ Files Modified:
- .aria/knowledge/ingestion/ingest_to_graphiti.py (v1.5.0 â†’ v1.7.0)
- .aria/knowledge/README.md (v1.6.0 â†’ v1.7.0)
- .aria/knowledge/tests/test_anthropic_graphiti.py â†’ test_deepseek_graphiti.py
- .aria/knowledge/mcp_servers/aria-graphiti-mcp-config.json

âœ… Validation:
- Unit tests passed (test_deepseek_graphiti.py)
- Integration test passed (test_single_episode.py)
- Micro-batch test passed (3 episodes, \$0 cost)
- No rate limit errors
- Graphiti operational with OpenRouter

ğŸŒ OpenRouter:
- Provider: https://openrouter.ai
- Model: deepseek/deepseek-r1:free
- Cost: \$0 (free tier)
- API Key: OPENROUTER_API_KEY (from .env)

ğŸ‰ Knowledge Graph is now FREE forever!

Refs: OPENROUTER-DEEPSEEK-MIGRATION-PLAN-2025-11-02.md"
```

#### 8.2. Push to GitHub

```bash
git push origin fix/cost-optimization-steph-knowledge
```

#### 8.3. CrÃ©er Implementation Report

**Fichier:** `.aria/docs/deployment/OPENROUTER-MIGRATION-COMPLETE-2025-11-02.md`
- RÃ©sumÃ© de la migration
- RÃ©sultats des tests
- Comparaison avant/aprÃ¨s
- LeÃ§ons apprises

**Validation Phase 8 :**
- âœ… Commits crÃ©Ã©s
- âœ… Pushed to GitHub
- âœ… Implementation report crÃ©Ã©

---

### Phase 9: Production Validation (Tonight 23:00)

**Test en production lors du nightly run :**

#### 9.1. Monitoring

**VÃ©rifier dans les logs (`automation/logs/nightly_reviews_*.log`) :**
```
ğŸ¤– Using DeepSeek R1 for LLM operations (via OpenRouter) - FREE! ğŸ‰
ğŸ’° Cost: $0/night (was $1-2 with Haiku 4.5)
ğŸŒ Provider: OpenRouter (https://openrouter.ai)
ğŸ”§ Set SEMAPHORE_LIMIT=5 (default for OpenRouter free tier)
âœ… Graphiti initialized (LLM: DeepSeek R1 FREE via OpenRouter, Embeddings: OpenAI)
```

#### 9.2. MÃ©triques

**Comparer avant/aprÃ¨s :**
| MÃ©trique | Haiku 4.5 (Avant) | DeepSeek R1 (AprÃ¨s) |
|----------|-------------------|---------------------|
| CoÃ»t/nuit | $1-2 | **$0** âœ… |
| Rate limits | Possibles | Moins probables |
| SEMAPHORE_LIMIT | 15 | 5 |
| Duration | ~2-3 min | ~3-5 min (acceptable) |

#### 9.3. Rollback Plan (si Ã©chec)

**Si problÃ¨me critique en production :**

```bash
# 1. Restaurer backup
cp .aria/backups/2025-11-02-pre-openrouter/ingest_to_graphiti.py \
   .aria/knowledge/ingestion/ingest_to_graphiti.py

# 2. Commit rollback
git add .aria/knowledge/ingestion/ingest_to_graphiti.py
git commit -m "revert: Rollback to Haiku 4.5 (OpenRouter issues)"
git push origin fix/cost-optimization-steph-knowledge

# 3. RedÃ©marrer services si nÃ©cessaire
```

**Validation Phase 9 :**
- â° Attendre nightly run (23:00)
- ğŸŒ… Audit demain matin
- âœ… Valider $0 cost
- âœ… Valider fonctionnement

---

## ğŸ“Š RÃ‰SUMÃ‰ COMPARATIF

### Avant Migration (Haiku 4.5)

| Aspect | Valeur |
|--------|--------|
| **Provider** | Anthropic (direct) |
| **ModÃ¨le** | claude-haiku-4-5-20251001 |
| **CoÃ»t Input** | $1/M tokens |
| **CoÃ»t Output** | $5/M tokens |
| **CoÃ»t/nuit** | **$1-2** (Knowledge Graph) |
| **CoÃ»t/an** | **$365-730** |
| **Metadata** | Tracking via Usage API |
| **SEMAPHORE_LIMIT** | 15 |
| **Rate Limits** | 4M tokens/min (Tier 4) |

### AprÃ¨s Migration (DeepSeek R1)

| Aspect | Valeur |
|--------|--------|
| **Provider** | OpenRouter |
| **ModÃ¨le** | deepseek/deepseek-r1:free |
| **CoÃ»t Input** | **$0** |
| **CoÃ»t Output** | **$0** |
| **CoÃ»t/nuit** | **$0** âœ… |
| **CoÃ»t/an** | **$0** âœ… |
| **Metadata** | N/A (coÃ»t $0) |
| **SEMAPHORE_LIMIT** | 5 (conservatif) |
| **Rate Limits** | Free tier limits (TBD) |

### Agents (INCHANGÃ‰S)

| Agent | Provider | ModÃ¨le | CoÃ»t |
|-------|----------|--------|------|
| ARIA | Anthropic | Sonnet 4.5 | $3/$15/M |
| CARO | Anthropic | Sonnet 4.5 | $3/$15/M |
| BOB | Anthropic | Sonnet 4.5 | $3/$15/M |
| STEPH | Anthropic | Sonnet 4.5 | $3/$15/M |
| PEPPER | Anthropic | Sonnet 4.5 | $3/$15/M |
| K2000 | Anthropic | Sonnet 4.5 | $3/$15/M |

**Note:** Les agents continuent d'utiliser Sonnet 4.5 (Anthropic direct) car ils nÃ©cessitent frontier intelligence.

---

## âš ï¸ RISQUES & MITIGATION

### Risque 1: QualitÃ© Entity Extraction

**Risque:** DeepSeek R1 moins performant que Haiku 4.5 pour entity extraction

**Mitigation:**
- âœ… Test validation avant production
- âœ… Comparer qualitÃ© entities extraites
- âœ… Rollback plan prÃªt si qualitÃ© insuffisante
- âœ… DeepSeek R1 suffisant pour structured extraction

**ProbabilitÃ©:** Faible (DeepSeek est capable)

### Risque 2: Rate Limits Free Tier

**Risque:** OpenRouter free tier peut avoir rate limits stricts

**Mitigation:**
- âœ… SEMAPHORE_LIMIT=5 (conservatif)
- âœ… SafeIngestionQueue delays (5 min entre steps)
- âœ… Nightly run = batch processing (pas real-time)
- âœ… Monitoring via logs

**ProbabilitÃ©:** Moyenne (mais mitigation efficace)

### Risque 3: StabilitÃ© OpenRouter

**Risque:** Service OpenRouter peut Ãªtre instable

**Mitigation:**
- âœ… Retry logic dans SafeIngestionQueue
- âœ… Exponential backoff implÃ©mentÃ©
- âœ… Backup vers Haiku 4.5 disponible
- âœ… OpenRouter = production-ready service

**ProbabilitÃ©:** Faible

### Risque 4: Changement Free Tier

**Risque:** OpenRouter peut changer/retirer free tier DeepSeek R1

**Mitigation:**
- âœ… Migration facile vers autre provider
- âœ… OpenAIGenericClient supporte n'importe quel provider OpenAI-compatible
- âœ… Alternative: DeepSeek R1 paid tier ($0.55/$2.19/M tokens)
- âœ… Alternative 2: Rollback Haiku 4.5

**ProbabilitÃ©:** Faible Ã  moyen terme

---

## âœ… SUCCESS CRITERIA

**Migration considÃ©rÃ©e rÃ©ussie si :**

1. âœ… **CoÃ»t $0** pour Knowledge Graph (vÃ©rifiÃ© dans Anthropic console)
2. âœ… **Nightly run complÃ¨te** sans erreur
3. âœ… **Entities extraites** correctement (qualitÃ© acceptable)
4. âœ… **Pas de rate limit 429** errors
5. âœ… **MCP tools fonctionnels** (search, facts, etc.)
6. âœ… **Duration acceptable** (< 10 min pour ingestion)
7. âœ… **Agents INCHANGÃ‰S** (toujours Sonnet 4.5)

**Si tous les critÃ¨res OK â†’ Migration permanente**  
**Si Ã©chec â†’ Rollback vers Haiku 4.5**

---

## ğŸ¯ TIMELINE

| Phase | DurÃ©e | Status |
|-------|-------|--------|
| Phase 1: Backup | 5 min | â³ Pending |
| Phase 2: Code Principal | 20 min | â³ Pending |
| Phase 3: Tests | 15 min | â³ Pending |
| Phase 4: Config MCP | 5 min | â³ Pending |
| Phase 5: Documentation | 10 min | â³ Pending |
| Phase 6: Env Variables | 2 min | â³ Pending |
| Phase 7: Test Validation | 20 min | â³ Pending |
| Phase 8: Commit & Docs | 10 min | â³ Pending |
| Phase 9: Production | Ce soir 23:00 | â³ Pending |
| **TOTAL** | **~90 minutes** | â³ Ready to execute |

---

## ğŸ“š RÃ‰FÃ‰RENCES

### Documentation OpenRouter
- Site: https://openrouter.ai
- Docs: https://openrouter.ai/docs
- Models: https://openrouter.ai/models
- DeepSeek R1: https://openrouter.ai/models/deepseek/deepseek-r1

### Documentation Graphiti
- OpenAIGenericClient: `graphiti_core.llm_client.openai_generic_client`
- LLMConfig: `graphiti_core.llm_client.config`
- Graphiti: `graphiti_core.Graphiti`

### Fichiers ModifiÃ©s
- `.aria/knowledge/ingestion/ingest_to_graphiti.py` (principal)
- `.aria/knowledge/README.md` (documentation)
- `.aria/knowledge/tests/test_deepseek_graphiti.py` (tests)
- `.aria/knowledge/mcp_servers/aria-graphiti-mcp-config.json` (config)

### Backups
- `.aria/backups/2025-11-02-pre-openrouter/` (rollback)

---

**Plan crÃ©Ã©:** Nov 2, 2025, 17:00 CET  
**Status:** ğŸ“‹ **COMPLET - Ready for execution**  
**DurÃ©e estimÃ©e:** 90 minutes  
**Next:** ExÃ©cuter Phase 1 (Backup)

---

*Ce plan permet de migrer le Knowledge Graph vers OpenRouter DeepSeek R1 (gratuit) tout en conservant les agents sur Sonnet 4.5 (Anthropic). Ã‰conomies annuelles : $365-730 !* ğŸ‰

