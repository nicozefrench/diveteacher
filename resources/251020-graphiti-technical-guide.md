# Graphiti - Guide Technique Complet pour Agent IA

**Version Document**: 1.0  
**Date**: Octobre 2025  
**Repository**: https://github.com/getzep/graphiti  
**Agent Target**: Claude Sonnet 4.5

---

## Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture et Concepts Fondamentaux](#architecture-et-concepts-fondamentaux)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [API Core et Patterns d'Utilisation](#api-core-et-patterns-dutilisation)
6. [Types d'Entit√©s et Edges Personnalis√©s](#types-dentit√©s-et-edges-personnalis√©s)
7. [Capacit√©s de Recherche](#capacit√©s-de-recherche)
8. [Serveur MCP (Model Context Protocol)](#serveur-mcp-model-context-protocol)
9. [API REST Server](#api-rest-server)
10. [Optimisation des Performances](#optimisation-des-performances)
11. [D√©veloppement et Contribution](#d√©veloppement-et-contribution)
12. [Ressources et Documentation](#ressources-et-documentation)

---

## Vue d'ensemble

### Qu'est-ce que Graphiti ?

Graphiti est un framework Python pour construire et interroger des **graphes de connaissances temporellement conscients** (temporal knowledge graphs), sp√©cifiquement con√ßu pour les agents IA op√©rant dans des environnements dynamiques.

**Caract√©ristiques Principales**:
- üîÑ **Mises √† jour incr√©mentales en temps r√©el** - Int√©gration imm√©diate de nouveaux √©pisodes sans recomputation batch
- üïí **Mod√®le bi-temporel** - Suivi explicite du temps d'occurrence ET d'ingestion des √©v√©nements
- üîç **Recherche hybride efficace** - Combine embeddings s√©mantiques, BM25 et travers√©e de graphe
- üéØ **Ontologie personnalisable** - D√©finition d'entit√©s via mod√®les Pydantic
- üìà **Scalabilit√©** - Traitement parall√®le optimis√© pour grandes volum√©tries
- üìä **Latence sub-seconde** - P95 √† ~300ms (sans appels LLM pendant la recherche)

### Diff√©rences avec GraphRAG

| Aspect | GraphRAG (Microsoft) | Graphiti |
|--------|---------------------|----------|
| **Use Case** | R√©sum√© de documents statiques | Gestion de donn√©es dynamiques |
| **Data Handling** | Traitement batch | Mises √† jour continues et incr√©mentales |
| **Structure** | Clusters d'entit√©s + r√©sum√©s communautaires | Donn√©es √©pisodiques + entit√©s s√©mantiques + communaut√©s |
| **Retrieval** | R√©sum√©s LLM s√©quentiels | Recherche hybride (s√©mantique, BM25, graphe) |
| **Latency** | Secondes √† dizaines de secondes | Typiquement < 1s |
| **Temporal Handling** | Timestamps basiques | Suivi bi-temporel explicite |
| **Contradiction Handling** | Jugements LLM via r√©sum√©s | Invalidation temporelle des edges |
| **Custom Entities** | Non | Oui, via Pydantic |

**Paper de R√©f√©rence**: [Zep: A Temporal Knowledge Graph Architecture for Agent Memory](https://arxiv.org/abs/2501.13956)

---

## Architecture et Concepts Fondamentaux

### Architecture du Graphe

Graphiti utilise un graphe de connaissances **G = (N, E, œÜ)** avec trois niveaux hi√©rarchiques:

```
G (Knowledge Graph)
‚îú‚îÄ‚îÄ Episode Subgraph (Ee, Ne)
‚îÇ   ‚îî‚îÄ‚îÄ Episodes ‚Üí Entity Nodes (bidirectional indices)
‚îú‚îÄ‚îÄ Semantic Entity Subgraph (Es, Ns)
‚îÇ   ‚îî‚îÄ‚îÄ Entity Nodes ‚Üî Fact Edges (relationships)
‚îî‚îÄ‚îÄ Community Subgraph (Ec, Nc)
    ‚îî‚îÄ‚îÄ Entity Communities (detected via graph algorithms)
```

### 1. Episodes

**D√©finition**: Unit√© discr√®te d'information repr√©sentant une interaction ou un √©v√©nement.

**Types d'Episodes**:
```python
from graphiti_core.nodes import EpisodeType

# 3 types support√©s
EpisodeType.text      # Texte brut
EpisodeType.json      # Donn√©es structur√©es JSON
EpisodeType.message   # Format conversationnel
```

**Structure**:
```python
episode = {
    'name': 'episode_identifier',
    'content': 'content_text_or_json',
    'type': EpisodeType.text,
    'description': 'context_description',
    'reference_time': datetime.now(),  # Temps de r√©f√©rence de l'√©v√©nement
    'group_id': 'user_123'  # Pour isolation multi-tenant
}
```

**Extraction depuis un Episode**:
- **Entit√©s**: Noeuds extraits (personnes, lieux, concepts)
- **Relations**: Edges/Facts entre entit√©s
- **Temporal markers**: M√©tadonn√©es temporelles

### 2. Entity Nodes (Entit√©s)

**Propri√©t√©s Core**:
```python
class EntityNode:
    uuid: str                    # Identifiant unique
    name: str                    # Nom de l'entit√©
    summary: str                 # R√©sum√© g√©n√©r√©
    created_at: datetime         # Timestamp cr√©ation syst√®me
    group_id: Optional[str]      # Isolation multi-tenant
    labels: List[str]            # Labels Neo4j (ex: ["Entity"])
    attributes: Dict             # Attributs personnalis√©s
    name_embedding: List[float]  # Embedding du nom
```

**Process de R√©solution d'Entit√©s**:
1. Extraction via LLM depuis l'√©pisode
2. Recherche hybride d'entit√©s similaires existantes
3. R√©solution via LLM (d√©tection de doublons)
4. Mise √† jour ou cr√©ation de l'entit√©

### 3. Entity Edges (Relations/Facts)

**D√©finition**: Repr√©sente une relation/fait entre deux entit√©s.

**Structure Temporelle (Bi-Temporal Model)**:
```python
class EntityEdge:
    uuid: str
    source_node_uuid: str        # Entit√© source
    target_node_uuid: str        # Entit√© cible
    name: str                    # Type de relation (ex: "WORKS_AT")
    fact: str                    # Phrase compl√®te du fait
    
    # TEMPORAL MODEL - Transaction Time (T')
    created_at: datetime         # Quand le fait a √©t√© cr√©√© dans le syst√®me
    expired_at: Optional[datetime]  # Quand le fait a √©t√© invalid√© dans le syst√®me
    
    # TEMPORAL MODEL - Valid Time (T)
    valid_at: datetime           # Quand le fait √©tait vrai dans le monde r√©el
    invalid_at: Optional[datetime]  # Quand le fait a cess√© d'√™tre vrai
    
    fact_embedding: List[float]  # Embedding pour recherche s√©mantique
    episodes: List[str]          # UUIDs des √©pisodes sources
```

**Invalidation Temporelle**:
Lorsqu'un nouveau fait contredit un fait existant:
- Le syst√®me utilise le LLM pour d√©tecter les contradictions
- Le fait existant est **invalid√©** (pas supprim√©)
- `invalid_at` est d√©fini au `valid_at` du fait invalidant
- Pr√©serve l'historique complet

### 4. Communities

**D√©finition**: Groupes d'entit√©s d√©tect√©s via algorithmes de d√©tection de communaut√© (Louvain, etc.).

**Utilit√©**:
- Organisation hi√©rarchique des entit√©s
- Am√©lioration des recherches contextuelles
- R√©sum√©s de haut niveau

---

## Installation

### Pr√©requis

**Syst√®me**:
- Python 3.10+
- Base de donn√©es graphe (au choix):
  - Neo4j 5.26+
  - FalkorDB 1.1.2+
  - Kuzu 0.11.2+
  - Amazon Neptune Database/Analytics + OpenSearch Serverless

**APIs**:
- Cl√© API OpenAI (par d√©faut) ou autre provider LLM
- Optionnel: Anthropic, Groq, Google Gemini

### Installation Base

```bash
# Via pip
pip install graphiti-core

# Via uv (recommand√©)
uv add graphiti-core
```

### Installation avec Database Backend

```bash
# Pour FalkorDB
pip install graphiti-core[falkordb]
# ou
uv add graphiti-core[falkordb]

# Pour Kuzu
pip install graphiti-core[kuzu]

# Pour Amazon Neptune
pip install graphiti-core[neptune]
```

### Installation avec LLM Providers

```bash
# Anthropic
pip install graphiti-core[anthropic]

# Google Gemini
pip install graphiti-core[google-genai]

# Groq
pip install graphiti-core[groq]

# Combinaison multiple
pip install graphiti-core[anthropic,google-genai,falkordb]
```

### Installation Neo4j

**Option 1: Neo4j Desktop** (recommand√© pour dev)
- T√©l√©charger: https://neo4j.com/download/
- Interface graphique pour g√©rer instances et databases

**Option 2: Docker**
```bash
docker run \
    --name neo4j \
    -p 7474:7474 -p 7687:7687 \
    -e NEO4J_AUTH=neo4j/your_password \
    neo4j:latest
```

**Option 3: FalkorDB via Docker**
```bash
docker run -p 6379:6379 -p 3000:3000 -it --rm falkordb/falkordb:latest
```

---

## Configuration

### Variables d'Environnement Core

```bash
# LLM Provider (OpenAI par d√©faut)
export OPENAI_API_KEY=your_openai_api_key

# Neo4j Connection
export NEO4J_URI=bolt://localhost:7687
export NEO4J_USER=neo4j
export NEO4J_PASSWORD=password

# FalkorDB Connection
export FALKORDB_URI=falkor://localhost:6379

# Amazon Neptune
export NEPTUNE_HOST=neptune-db://<cluster-endpoint>  # ou neptune-graph://<graph-id>
export NEPTUNE_PORT=8182  # optionnel
export AOSS_HOST=<opensearch-serverless-host>
export AOSS_PORT=443  # optionnel

# Performance Tuning
export SEMAPHORE_LIMIT=10  # Limite de concurrence (d√©faut: 10)

# Telemetry (opt-out)
export GRAPHITI_TELEMETRY_ENABLED=false
```

### Configuration Database Driver

#### Neo4j

```python
from graphiti_core import Graphiti
from graphiti_core.driver.neo4j_driver import Neo4jDriver

# Driver avec database custom
driver = Neo4jDriver(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password",
    database="my_custom_database"  # D√©faut: "neo4j"
)

graphiti = Graphiti(graph_driver=driver)
```

#### FalkorDB

```python
from graphiti_core.driver.falkordb_driver import FalkorDriver

driver = FalkorDriver(
    host="localhost",
    port=6379,
    username="falkor_user",  # Optionnel
    password="falkor_password",  # Optionnel
    database="my_custom_graph"  # D√©faut: "default_db"
)

graphiti = Graphiti(graph_driver=driver)
```

#### Kuzu

```python
from graphiti_core.driver.kuzu_driver import KuzuDriver

driver = KuzuDriver(db="/tmp/graphiti.kuzu")
graphiti = Graphiti(graph_driver=driver)
```

#### Amazon Neptune

```python
from graphiti_core.driver.neptune_driver import NeptuneDriver

driver = NeptuneDriver(
    host="neptune-db://<cluster-endpoint>",  # ou neptune-graph://
    aoss_host="<opensearch-serverless-host>",
    port=8182,  # D√©faut
    aoss_port=443  # D√©faut
)

graphiti = Graphiti(graph_driver=driver)
```

### Configuration LLM Provider

#### OpenAI (D√©faut)

```python
from graphiti_core import Graphiti

# Configuration simple (utilise OPENAI_API_KEY)
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password"
)
```

#### Azure OpenAI

```python
from openai import AsyncAzureOpenAI
from graphiti_core import Graphiti
from graphiti_core.llm_client import LLMConfig, OpenAIClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

# Configuration Azure
api_key = "<your-api-key>"
api_version = "2024-02-01"
llm_endpoint = "https://your-llm-resource.openai.azure.com/"
embedding_endpoint = "https://your-embedding-resource.openai.azure.com/"

# Clients Azure s√©par√©s
llm_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=llm_endpoint
)

embedding_client_azure = AsyncAzureOpenAI(
    api_key=api_key,
    api_version=api_version,
    azure_endpoint=embedding_endpoint
)

# Config LLM
azure_llm_config = LLMConfig(
    small_model="gpt-4.1-nano",  # Nom de d√©ploiement Azure
    model="gpt-4.1-mini",        # Nom de d√©ploiement Azure
)

# Init Graphiti
graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=OpenAIClient(
        config=azure_llm_config,
        client=llm_client_azure
    ),
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            embedding_model="text-embedding-3-small-deployment"
        ),
        client=embedding_client_azure
    ),
    cross_encoder=OpenAIRerankerClient(
        config=LLMConfig(model=azure_llm_config.small_model),
        client=llm_client_azure
    )
)
```

**‚ö†Ô∏è IMPORTANT Azure**: N√©cessite opt-in API v1 pour structured outputs. Voir: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle

#### Google Gemini

```bash
uv add "graphiti-core[google-genai]"
```

```python
from graphiti_core import Graphiti
from graphiti_core.llm_client.gemini_client import GeminiClient, LLMConfig
from graphiti_core.embedder.gemini import GeminiEmbedder, GeminiEmbedderConfig
from graphiti_core.cross_encoder.gemini_reranker_client import GeminiRerankerClient

api_key = "<your-google-api-key>"

graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=GeminiClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.0-flash"
        )
    ),
    embedder=GeminiEmbedder(
        config=GeminiEmbedderConfig(
            api_key=api_key,
            embedding_model="embedding-001"
        )
    ),
    cross_encoder=GeminiRerankerClient(
        config=LLMConfig(
            api_key=api_key,
            model="gemini-2.5-flash-lite-preview-06-17"
        )
    )
)
```

#### Ollama (Local LLMs)

```bash
# Installer les mod√®les
ollama pull deepseek-r1:7b
ollama pull nomic-embed-text

# Lancer Ollama
ollama serve
```

```python
from graphiti_core import Graphiti
from graphiti_core.llm_client.config import LLMConfig
from graphiti_core.llm_client.openai_generic_client import OpenAIGenericClient
from graphiti_core.embedder.openai import OpenAIEmbedder, OpenAIEmbedderConfig
from graphiti_core.cross_encoder.openai_reranker_client import OpenAIRerankerClient

llm_config = LLMConfig(
    api_key="ollama",  # Placeholder
    model="deepseek-r1:7b",
    small_model="deepseek-r1:7b",
    base_url="http://localhost:11434/v1"
)

llm_client = OpenAIGenericClient(config=llm_config)

graphiti = Graphiti(
    "bolt://localhost:7687",
    "neo4j",
    "password",
    llm_client=llm_client,
    embedder=OpenAIEmbedder(
        config=OpenAIEmbedderConfig(
            api_key="ollama",
            embedding_model="nomic-embed-text",
            embedding_dim=768,
            base_url="http://localhost:11434/v1"
        )
    ),
    cross_encoder=OpenAIRerankerClient(
        client=llm_client,
        config=llm_config
    )
)
```

---

## API Core et Patterns d'Utilisation

### Pattern Basique d'Utilisation

```python
import asyncio
import logging
from datetime import datetime, timezone
from graphiti_core import Graphiti
from graphiti_core.nodes import EpisodeType

logging.basicConfig(level=logging.INFO)

async def main():
    # 1. INITIALIZATION
    graphiti = Graphiti(
        "bolt://localhost:7687",
        "neo4j",
        "password"
    )
    
    # 2. BUILD INDICES (une seule fois)
    await graphiti.build_indices_and_constraints()
    
    # 3. ADD EPISODES
    episodes = [
        {
            'content': 'Kamala Harris was the attorney general of California. '
                      'She was previously the district attorney for San Francisco.',
            'type': EpisodeType.text,
            'description': 'podcast transcript'
        },
        {
            'content': 'As AG, Harris was in office from January 3, 2011 ‚Äì January 3, 2017',
            'type': EpisodeType.text,
            'description': 'podcast transcript'
        },
        {
            'content': {
                'name': 'Gavin Newsom',
                'position': 'Governor',
                'state': 'California'
            },
            'type': EpisodeType.json,
            'description': 'podcast metadata'
        }
    ]
    
    for i, episode in enumerate(episodes):
        await graphiti.add_episode(
            name=f"episode_{i}",
            episode_body=episode['content'],
            source=episode['type'],
            source_description=episode['description'],
            reference_time=datetime.now(timezone.utc)
        )
    
    # 4. BUILD COMMUNITIES (optionnel, pour meilleure organisation)
    await graphiti.build_communities()
    
    # 5. SEARCH
    results = await graphiti.search('Who was the California Attorney General?')
    
    for edge in results:
        print(f"Fact: {edge.fact}")
        print(f"Relation: {edge.name}")
        print(f"Valid: {edge.valid_at} -> {edge.invalid_at}")
    
    # 6. CLOSE
    await graphiti.close()

if __name__ == "__main__":
    asyncio.run(main())
```

### M√©thodes Core de l'API Graphiti

#### `build_indices_and_constraints()`

```python
await graphiti.build_indices_and_constraints()
```
- **Usage**: √Ä appeler **une seule fois** lors de la premi√®re initialisation
- **Effet**: Cr√©e les indices et contraintes n√©cessaires dans la database
- **Requis**: Avant toute autre op√©ration

#### `add_episode()`

```python
await graphiti.add_episode(
    name: str,                      # Identifiant de l'√©pisode
    episode_body: str | dict,       # Contenu (texte ou JSON)
    source: EpisodeType,            # text, json, ou message
    source_description: str,        # Description du contexte
    reference_time: datetime,       # Timestamp de r√©f√©rence de l'√©v√©nement
    group_id: Optional[str] = None, # Pour isolation multi-tenant
    entity_types: Optional[List[Type[BaseModel]]] = None,  # Types custom
    edge_types: Optional[List[Type[BaseModel]]] = None     # Types custom
)
```

**Processus interne**:
1. Extraction d'entit√©s via LLM
2. R√©solution d'entit√©s (d√©doublonnage)
3. Extraction de facts/edges
4. D√©doublonnage d'edges
5. D√©tection de contradictions et invalidation temporelle
6. Insertion dans le graphe

#### `search()`

```python
results = await graphiti.search(
    query: str,                              # Requ√™te de recherche
    num_results: int = 10,                   # Nombre de r√©sultats
    group_ids: Optional[List[str]] = None,   # Filtrer par group_id
    center_node_uuid: Optional[str] = None,  # Pour reranking par distance
    search_config: Optional[SearchConfig] = None  # Config avanc√©e
)
# Returns: List[EntityEdge]
```

**M√©thode de recherche**: Hybrid Search (RRF - Reciprocal Rank Fusion)
- Recherche s√©mantique (embeddings)
- Recherche BM25 (full-text)
- Fusion et reranking

#### `search_nodes()`

```python
nodes = await graphiti.search_nodes(
    query: str,
    num_results: int = 10,
    group_ids: Optional[List[str]] = None,
    search_config: Optional[SearchConfig] = None
)
# Returns: List[EntityNode]
```

Recherche directement les noeuds d'entit√©s (au lieu des edges).

#### `build_communities()`

```python
await graphiti.build_communities()
```
- D√©tecte et construit les communaut√©s d'entit√©s
- Am√©liore les recherches contextuelles
- √Ä appeler apr√®s ingestion de plusieurs √©pisodes

#### `close()`

```python
await graphiti.close()
```
Ferme proprement les connexions database.

---

## Types d'Entit√©s et Edges Personnalis√©s

### D√©finition via Pydantic

**Exemple - Types d'Entit√©s Custom**:

```python
from pydantic import BaseModel, Field
from typing import Optional

class Person(BaseModel):
    """Represents a person entity"""
    full_name: str = Field(description="Full name of the person")
    age: Optional[int] = Field(None, description="Age in years")
    occupation: Optional[str] = Field(None, description="Current job/role")
    email: Optional[str] = Field(None, description="Email address")

class Organization(BaseModel):
    """Represents an organization or company"""
    name: str = Field(description="Organization name")
    industry: Optional[str] = Field(None, description="Industry sector")
    founded_year: Optional[int] = Field(None, description="Year founded")
    headquarters: Optional[str] = Field(None, description="Location of HQ")

class Project(BaseModel):
    """Represents a project or initiative"""
    title: str = Field(description="Project title")
    status: Optional[str] = Field(None, description="Current status")
    deadline: Optional[str] = Field(None, description="Target deadline")
```

**Exemple - Types d'Edges Custom**:

```python
class WorksAt(BaseModel):
    """Represents employment relationship"""
    role: str = Field(description="Job title/role")
    start_date: Optional[str] = Field(None, description="Start date")
    department: Optional[str] = Field(None, description="Department")

class LeadsProject(BaseModel):
    """Represents project leadership"""
    responsibility: str = Field(description="Leadership responsibility")
    budget: Optional[float] = Field(None, description="Budget in USD")
```

### Utilisation des Types Custom

```python
from graphiti_core.nodes import EpisodeType

# Liste des types d'entit√©s
entity_types = [Person, Organization, Project]

# Liste des types d'edges
edge_types = [WorksAt, LeadsProject]

# Ajout d'√©pisode avec types custom
await graphiti.add_episode(
    name="company_update",
    episode_body="""
        Alice Johnson works at TechCorp as a Senior Engineer. 
        She leads the AI Platform project with a budget of $2M.
        The project deadline is December 2025.
    """,
    source=EpisodeType.text,
    source_description="company records",
    reference_time=datetime.now(timezone.utc),
    entity_types=entity_types,
    edge_types=edge_types
)
```

### Recherche Filtr√©e par Types

```python
from graphiti_core.search.search_filters import SearchFilters

# Filtrer uniquement les personnes
filters = SearchFilters(
    entity_labels=["Person"]  # Correspond au nom de la classe
)

results = await graphiti.search(
    query="Who works on AI projects?",
    num_results=10,
    search_config=SearchConfig(filters=filters)
)
```

### ‚ö†Ô∏è Limitations Actuelles (v0.17.x)

**Issue connue**: Les propri√©t√©s custom ne sont pas toujours persist√©es dans Neo4j
- Les labels sp√©cifiques (`:Person`, `:Organization`) peuvent √™tre absents
- Seules les propri√©t√©s standard sont sauvegard√©es
- R√©f√©rence: https://github.com/getzep/graphiti/issues/567
- **Workaround**: Surveiller les updates futures ou contribuer au fix

---

## Capacit√©s de Recherche

### Types de Recherche

#### 1. Hybrid Search (Par D√©faut)

Combine 3 m√©thodes:
- **Semantic Search**: Embeddings + cosine similarity
- **Full-Text Search**: BM25
- **Fusion**: Reciprocal Rank Fusion (RRF)

```python
results = await graphiti.search(
    query="California officials",
    num_results=10
)
```

#### 2. Search Recipes (Configurations Pr√©d√©finies)

```python
from graphiti_core.search.search_config_recipes import (
    NODE_HYBRID_SEARCH_RRF,  # Recherche de noeuds avec RRF
    EDGE_HYBRID_SEARCH_RRF,  # Recherche d'edges avec RRF
    # ... autres recipes disponibles
)

nodes = await graphiti.search_nodes(
    query="software engineers",
    num_results=10,
    search_config=NODE_HYBRID_SEARCH_RRF
)
```

#### 3. Reranking Strategies

**Node Distance Reranking**: R√©ordonne par distance graphe depuis un noeud central

```python
# 1. Obtenir un r√©sultat initial
initial_results = await graphiti.search("tech companies", num_results=5)
center_node_uuid = initial_results[0].source_node_uuid

# 2. Reranker par distance depuis ce noeud
reranked_results = await graphiti.search(
    query="tech companies",
    num_results=20,
    center_node_uuid=center_node_uuid
)
```

**Autres strat√©gies de reranking**:
- **RRF (Reciprocal Rank Fusion)**: D√©faut, rapide
- **MMR (Maximal Marginal Relevance)**: Diversit√© des r√©sultats
- **EpisodeMentions**: Par fr√©quence de mentions dans √©pisodes
- **CrossEncoder**: Meilleure qualit√© mais plus lent (appel LLM)

### SearchConfig Avanc√©

```python
from graphiti_core.search.search_config import SearchConfig
from graphiti_core.search.search_filters import SearchFilters
from graphiti_core.search.search_methods import SearchMethod
from graphiti_core.search.reranker import RerankMethod

config = SearchConfig(
    # M√©thodes de recherche
    search_methods=[
        SearchMethod.cosine_similarity,
        SearchMethod.bm25,
        SearchMethod.bfs  # Breadth-First Search
    ],
    
    # Nombre de r√©sultats par m√©thode
    num_results=50,
    
    # Reranking
    reranker=RerankMethod.rrf,
    
    # Filtres
    filters=SearchFilters(
        # Filtrer par labels
        entity_labels=["Person", "Organization"],
        
        # Filtrer par plage temporelle (valid_at)
        start_date=datetime(2020, 1, 1),
        end_date=datetime(2024, 12, 31),
        
        # Filtrer par group_id
        group_ids=["tenant_123"]
    )
)

results = await graphiti.search(
    query="project leaders",
    num_results=10,
    search_config=config
)
```

### Recherche Temporelle

**Point-in-Time Query**: Retrouver l'√©tat du graphe √† un moment pr√©cis

```python
from datetime import datetime

# Rechercher ce qui √©tait vrai au 1er janvier 2023
filters = SearchFilters(
    start_date=datetime(2023, 1, 1),
    end_date=datetime(2023, 1, 1)
)

results = await graphiti.search(
    query="California officials",
    search_config=SearchConfig(filters=filters)
)

# Les r√©sultats ne contiendront que des edges:
# - Avec valid_at <= 2023-01-01
# - Sans invalid_at OU invalid_at > 2023-01-01
```

---

## Serveur MCP (Model Context Protocol)

### Pr√©sentation

Le serveur MCP Graphiti expose les capacit√©s du framework via le protocole MCP, permettant aux assistants IA (Claude Desktop, Cursor, etc.) d'interagir avec le graphe de connaissances.

**Documentation**: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md

### Fonctionnalit√©s Expos√©es

**Tools MCP disponibles**:
1. `add_episode` - Ajouter un √©pisode au graphe
2. `search_nodes` - Rechercher des noeuds d'entit√©s
3. `search_facts` - Rechercher des facts/edges
4. `delete_entity_edge` - Supprimer un edge
5. `delete_episode` - Supprimer un √©pisode
6. `retrieve_episodes` - R√©cup√©rer des √©pisodes
7. `get_entity` - Obtenir une entit√© par UUID
8. Gestion de groupes (group management)
9. Op√©rations de maintenance

### Installation

```bash
# Installer uv (gestionnaire de packages)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Cloner le repo
git clone https://github.com/getzep/graphiti.git
cd graphiti/mcp_server
```

### Configuration Claude Desktop

**Fichier**: `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS)

```json
{
  "mcpServers": {
    "graphiti": {
      "command": "uv",
      "args": [
        "run",
        "/ABSOLUTE/PATH/TO/graphiti/mcp_server/graphiti_mcp_server.py",
        "--transport",
        "sse"
      ],
      "env": {
        "NEO4J_URI": "bolt://localhost:7687",
        "NEO4J_USER": "neo4j",
        "NEO4J_PASSWORD": "your_password",
        "OPENAI_API_KEY": "${OPENAI_API_KEY}",
        "MODEL_NAME": "gpt-4.1-mini",
        "GRAPHITI_TELEMETRY_ENABLED": "false"
      }
    }
  }
}
```

### Configuration Cursor

**Fichier**: `.cursor/mcp.json` dans votre projet

```json
{
  "mcpServers": {
    "graphiti": {
      "command": "uv",
      "args": [
        "run",
        "/ABSOLUTE/PATH/TO/graphiti/mcp_server/graphiti_mcp_server.py",
        "--transport",
        "stdio"
      ],
      "env": {
        "NEO4J_URI": "bolt://localhost:7687",
        "NEO4J_USER": "neo4j",
        "NEO4J_PASSWORD": "your_password",
        "OPENAI_API_KEY": "${OPENAI_API_KEY}",
        "MODEL_NAME": "gpt-4.1-mini"
      }
    }
  }
}
```

### D√©ploiement Docker

**Fichier**: `.env`
```bash
OPENAI_API_KEY=your_openai_api_key_here
MODEL_NAME=gpt-4.1-mini
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password
```

**Fichier**: `docker-compose.yml`
```yaml
version: '3.8'

services:
  neo4j:
    image: neo4j:latest
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      NEO4J_AUTH: neo4j/your_neo4j_password
    volumes:
      - neo4j_data:/data

  graphiti-mcp:
    build: .
    ports:
      - "8000:8000"
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      MODEL_NAME: ${MODEL_NAME}
      NEO4J_URI: ${NEO4J_URI}
      NEO4J_USER: ${NEO4J_USER}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD}
    depends_on:
      - neo4j

volumes:
  neo4j_data:
```

```bash
docker-compose up -d
```

### Utilisation depuis Claude

Une fois configur√©, Claude peut interagir avec Graphiti:

```
User: "Remember that I work at TechCorp as a Senior Engineer on the AI Platform project"

Claude: [Utilise automatiquement l'outil add_episode du MCP server]

User: "What do you know about my work?"

Claude: [Utilise search_facts pour r√©cup√©rer les informations]
```

---

## API REST Server

### Pr√©sentation

Le r√©pertoire `server/` contient une API REST FastAPI pour interagir avec Graphiti via HTTP.

**Documentation**: https://github.com/getzep/graphiti/blob/main/server/README.md

### Installation

```bash
cd graphiti/server
pip install -r requirements.txt
```

### Configuration

**Fichier**: `.env` ou variables d'environnement

```bash
# Database
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# LLM
OPENAI_API_KEY=your_key
MODEL_NAME=gpt-4.1-mini

# Server
HOST=0.0.0.0
PORT=8000
```

### Lancement

```bash
cd server
uvicorn graph_service.main:app --reload --host 0.0.0.0 --port 8000
```

### Endpoints Principaux

**Documentation Auto-g√©n√©r√©e**: http://localhost:8000/docs (Swagger UI)

**Ingestion**:
- `POST /episodes` - Ajouter un √©pisode
- `DELETE /episodes/{uuid}` - Supprimer un √©pisode

**Recherche**:
- `GET /search` - Recherche hybride d'edges
- `GET /search/nodes` - Recherche de noeuds

**Entit√©s**:
- `GET /entities/{uuid}` - Obtenir une entit√©
- `GET /entities` - Lister les entit√©s

**Graphe**:
- `POST /communities` - Construire les communaut√©s
- `GET /health` - Status du service

### Exemple d'Utilisation

```python
import requests

BASE_URL = "http://localhost:8000"

# Ajouter un √©pisode
response = requests.post(
    f"{BASE_URL}/episodes",
    json={
        "name": "meeting_notes",
        "content": "Alice discussed the Q4 roadmap with Bob",
        "source": "text",
        "source_description": "meeting notes",
        "group_id": "team_alpha"
    }
)

print(response.json())

# Rechercher
response = requests.get(
    f"{BASE_URL}/search",
    params={
        "query": "Q4 roadmap",
        "num_results": 10
    }
)

results = response.json()
for edge in results["edges"]:
    print(edge["fact"])
```

---

## Optimisation des Performances

### 1. Ajuster la Concurrence (SEMAPHORE_LIMIT)

**Probl√®me**: Graphiti utilise des appels LLM concurrents. Par d√©faut, `SEMAPHORE_LIMIT=10` pour √©viter les erreurs 429 (rate limit).

**Solution**:
```bash
# Si vous avez un tier avec plus de throughput
export SEMAPHORE_LIMIT=50

# Si vous rencontrez des 429
export SEMAPHORE_LIMIT=5
```

**Impact**: Directement sur la vitesse d'ingestion d'√©pisodes.

### 2. Batch Processing d'Episodes

```python
import asyncio

async def ingest_batch(graphiti, episodes_batch):
    tasks = []
    for episode in episodes_batch:
        task = graphiti.add_episode(
            name=episode['name'],
            episode_body=episode['content'],
            source=episode['type'],
            source_description=episode['description'],
            reference_time=episode['timestamp']
        )
        tasks.append(task)
    
    # Ex√©cute en parall√®le (limit√© par SEMAPHORE_LIMIT)
    await asyncio.gather(*tasks)

# Usage
await ingest_batch(graphiti, batch_of_100_episodes)
```

### 3. Optimisation Neo4j

**Indices recommand√©s** (cr√©√©s automatiquement par `build_indices_and_constraints()`):
- Index sur `uuid` pour EntityNode et EntityEdge
- Index sur `name_embedding` pour recherche vectorielle
- Index sur `fact_embedding` pour recherche vectorielle
- Contrainte d'unicit√© sur `uuid`

**Configuration Neo4j** (`neo4j.conf`):
```ini
# Augmenter la m√©moire heap
dbms.memory.heap.initial_size=2G
dbms.memory.heap.max_size=4G

# Augmenter le page cache
dbms.memory.pagecache.size=2G

# Pour recherches parall√®les (Enterprise Edition uniquement)
# dbms.cypher.parallel_runtime_enabled=true
```

### 4. Strat√©gies de Recherche

**Trade-offs**:
- **RRF (Reciprocal Rank Fusion)**: ‚ö° Rapide, bonne qualit√©
- **MMR (Maximal Marginal Relevance)**: üéØ Diversit√©, moyen
- **NodeDistance**: üîó Contexte graphe, moyen
- **CrossEncoder**: üéñÔ∏è Meilleure qualit√©, ‚è±Ô∏è plus lent (appel LLM)

**Recommandation**: Utiliser RRF par d√©faut, CrossEncoder pour queries critiques.

### 5. Caching et R√©utilisation

```python
# R√©utiliser la connexion Graphiti
class GraphitiManager:
    _instance = None
    
    @classmethod
    async def get_instance(cls):
        if cls._instance is None:
            cls._instance = Graphiti(
                "bolt://localhost:7687",
                "neo4j",
                "password"
            )
            await cls._instance.build_indices_and_constraints()
        return cls._instance
    
    @classmethod
    async def close(cls):
        if cls._instance:
            await cls._instance.close()
            cls._instance = None
```

---

## D√©veloppement et Contribution

### Structure du Repository

```
graphiti/
‚îú‚îÄ‚îÄ graphiti_core/          # Package core
‚îÇ   ‚îú‚îÄ‚îÄ llm_client/         # Clients LLM (OpenAI, Gemini, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ embedder/           # Embedders (OpenAI, Voyage, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ driver/             # Drivers database (Neo4j, FalkorDB, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ search/             # Moteur de recherche
‚îÇ   ‚îú‚îÄ‚îÄ nodes.py            # D√©finitions EntityNode, EntityEdge, Episode
‚îÇ   ‚îú‚îÄ‚îÄ graphiti.py         # Classe principale Graphiti
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ examples/               # Exemples d'utilisation
‚îÇ   ‚îî‚îÄ‚îÄ quickstart/         # Quickstart avec Neo4j, FalkorDB, Neptune
‚îú‚îÄ‚îÄ mcp_server/             # Serveur MCP
‚îú‚îÄ‚îÄ server/                 # API REST FastAPI
‚îú‚îÄ‚îÄ tests/                  # Tests unitaires et d'int√©gration
‚îú‚îÄ‚îÄ pyproject.toml          # Configuration du projet
‚îî‚îÄ‚îÄ README.md
```

### Setup D√©veloppement

```bash
# Cloner le repo
git clone https://github.com/getzep/graphiti.git
cd graphiti

# Installer avec d√©pendances dev
uv pip install -e ".[dev]"

# Ou avec pip
pip install -e ".[dev]"

# Installer pre-commit hooks
pre-commit install
```

### Lancer les Tests

```bash
# Tests unitaires
pytest tests/

# Tests avec coverage
pytest --cov=graphiti_core tests/

# Tests sp√©cifiques
pytest tests/test_graphiti.py::test_add_episode
```

### Contribution Guidelines

**R√©f√©rence**: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md

**Process**:
1. Fork le repository
2. Cr√©er une branche feature: `git checkout -b feature/ma-nouvelle-fonctionnalite`
3. Faire les modifications avec tests
4. Commit: `git commit -m "feat: ajout de X"`
5. Push: `git push origin feature/ma-nouvelle-fonctionnalite`
6. Ouvrir une Pull Request

**Standards**:
- Type hints Python obligatoires
- Docstrings style Google
- Tests pour toute nouvelle fonctionnalit√©
- Pre-commit hooks doivent passer (black, ruff, mypy)

### Roadmap Actuel

**En d√©veloppement**:
1. **Custom graph schemas**: Permettre sch√©mas de noeuds/edges enti√®rement custom
2. **Enhanced retrieval**: Options de recherche plus robustes
3. **Test coverage**: Augmenter la couverture de tests
4. **MCP Server improvements**: Nouvelles fonctionnalit√©s MCP

---

## Ressources et Documentation

### Liens Officiels

**Repository Principal**:
- GitHub: https://github.com/getzep/graphiti
- PyPI: https://pypi.org/project/graphiti-core/

**Documentation**:
- Docs Officielles: https://help.getzep.com/graphiti/
- Quick Start: https://help.getzep.com/graphiti/getting-started/quick-start
- API Reference: https://help.getzep.com/graphiti/api-reference
- Custom Entities: https://help.getzep.com/graphiti/core-concepts/custom-entity-and-edge-types

**Exemples**:
- Quickstart: https://github.com/getzep/graphiti/tree/main/examples/quickstart
- Custom Entities: https://github.com/getzep/graphiti/tree/main/examples/custom_entity_edge_types

**MCP Server**:
- MCP README: https://github.com/getzep/graphiti/blob/main/mcp_server/README.md
- MCP Documentation: https://help.getzep.com/graphiti/getting-started/mcp-server

**API REST**:
- Server README: https://github.com/getzep/graphiti/blob/main/server/README.md

### Papers et Articles

**Research Paper**:
- [Zep: A Temporal Knowledge Graph Architecture for Agent Memory (arXiv)](https://arxiv.org/abs/2501.13956)
- [Zep: A Temporal Knowledge Graph Architecture for Agent Memory (HTML)](https://arxiv.org/html/2501.13956v1)
- Blog Post: https://blog.getzep.com/state-of-the-art-agent-memory/

**Articles Techniques**:
- [Graphiti: Temporal Knowledge Graphs for Agentic Apps](https://blog.getzep.com/graphiti-knowledge-graphs-for-agents/)
- [Graphiti: Knowledge Graph Memory for an Agentic World (Neo4j)](https://neo4j.com/blog/developer/graphiti-knowledge-graph-memory/)

### Communaut√©

**Discord**:
- Zep Discord: https://discord.com/invite/W8Kw6bsgXQ
- Channel: `#Graphiti`

**GitHub**:
- Issues: https://github.com/getzep/graphiti/issues
- Discussions: https://github.com/getzep/graphiti/discussions
- Contributing: https://github.com/getzep/graphiti/blob/main/CONTRIBUTING.md

### Bases de Donn√©es Support√©es

**Neo4j**:
- Neo4j Desktop: https://neo4j.com/download/
- Neo4j Documentation: https://neo4j.com/docs/

**FalkorDB**:
- Website: https://falkordb.com/
- Documentation: https://docs.falkordb.com/

**Kuzu**:
- Website: https://kuzudb.com/
- Documentation: https://kuzudb.com/docs/

**Amazon Neptune**:
- Documentation: https://docs.aws.amazon.com/neptune/
- Developer Resources: https://aws.amazon.com/neptune/developer-resources/

### LLM Providers

**OpenAI**:
- API Docs: https://platform.openai.com/docs/
- Structured Outputs: https://platform.openai.com/docs/guides/structured-outputs

**Azure OpenAI**:
- API Lifecycle: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle

**Google Gemini**:
- API Docs: https://ai.google.dev/docs
- Gemini Models: https://ai.google.dev/models/gemini

**Anthropic**:
- API Docs: https://docs.anthropic.com/

**Ollama**:
- Website: https://ollama.ai/
- Models: https://ollama.ai/library

---

## Annexes

### Checklist d'Installation

- [ ] Python 3.10+ install√©
- [ ] Database graphe install√©e et running (Neo4j/FalkorDB/Kuzu/Neptune)
- [ ] Cl√© API LLM configur√©e (OPENAI_API_KEY ou autre)
- [ ] `graphiti-core` install√© avec extras appropri√©s
- [ ] Variables d'environnement configur√©es
- [ ] Test de connexion database r√©ussi
- [ ] `build_indices_and_constraints()` ex√©cut√©

### Checklist de Production

- [ ] SEMAPHORE_LIMIT ajust√© selon throughput LLM
- [ ] Database backups configur√©s
- [ ] Monitoring Neo4j configur√© (si applicable)
- [ ] Logging configur√© (niveau INFO minimum)
- [ ] Group IDs utilis√©s pour isolation multi-tenant
- [ ] Telemetry d√©sactiv√©e si n√©cessaire
- [ ] Secrets manag√©s via vault (pas en env vars hardcod√©es)
- [ ] Rate limits LLM provider v√©rifi√©s
- [ ] Strat√©gie de reranking choisie (RRF vs CrossEncoder)
- [ ] Build communities ex√©cut√© r√©guli√®rement

### Troubleshooting Commun

**Probl√®me**: `Graph not found: default_db`
```python
# Solution: Sp√©cifier le bon nom de database
driver = Neo4jDriver(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password",
    database="neo4j"  # Pas "default_db"
)
```

**Probl√®me**: Erreurs 429 (Rate Limit) du LLM
```bash
# Solution: R√©duire la concurrence
export SEMAPHORE_LIMIT=5
```

**Probl√®me**: Recherches lentes
```python
# Solution 1: Utiliser RRF au lieu de CrossEncoder
config = SearchConfig(reranker=RerankMethod.rrf)

# Solution 2: R√©duire num_results
results = await graphiti.search(query, num_results=5)
```

**Probl√®me**: Types custom non persist√©s dans Neo4j
```python
# Workaround: Utiliser attributes dict pour stocker donn√©es custom
# Surveiller l'issue: https://github.com/getzep/graphiti/issues/567
```

**Probl√®me**: Structured Outputs √©chouent avec Azure OpenAI
```
# Solution: V√©rifier que le d√©ploiement a opt-in pour API v1
# Voir: https://learn.microsoft.com/en-us/azure/ai-foundry/openai/api-version-lifecycle
```

---

## Notes Finales pour l'Agent IA

### Principes de D√©veloppement

1. **Toujours utiliser des contexts managers async** pour les connexions
2. **Utiliser des group_ids** pour isolation multi-tenant d√®s le d√©but
3. **Penser temporellement** - chaque fait a une dur√©e de validit√©
4. **Privil√©gier la recherche hybride (RRF)** pour le meilleur rapport qualit√©/performance
5. **Construire les communities r√©guli√®rement** pour am√©liorer les recherches contextuelles
6. **Documenter les types custom** avec des descriptions Field() claires

### Patterns Anti-patterns

**‚ùå √Ä √âviter**:
- Appeler `build_indices_and_constraints()` √† chaque d√©marrage
- Ignorer les group_ids dans une application multi-utilisateur
- Utiliser CrossEncoder pour toutes les recherches (lent)
- Stocker des donn√©es sensibles directement dans les facts
- Cr√©er de nouveaux drivers Graphiti pour chaque requ√™te

**‚úÖ √Ä Faire**:
- R√©utiliser une instance Graphiti globale
- Fermer proprement les connexions avec `await graphiti.close()`
- Utiliser des types custom pour structurer le domaine
- Exploiter la recherche temporelle pour queries historiques
- Monitorer les rate limits LLM et ajuster SEMAPHORE_LIMIT

### M√©triques de Performance Cibles

- **Ingestion**: ~1-5 secondes par √©pisode (d√©pend de SEMAPHORE_LIMIT et LLM)
- **Recherche**: < 1 seconde (P95 √† 300ms)
- **Build Communities**: Variable selon taille du graphe

---

**Derni√®re Mise √† Jour**: Octobre 2025  
**Version Graphiti**: 0.17.x  
**Maintainer**: Zep AI (https://www.getzep.com)  
**License**: M√™me licence que le projet parent Graphiti

